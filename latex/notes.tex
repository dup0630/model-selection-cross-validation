\documentclass[11pt, letter paper]{article}
\usepackage{amsmath,amsthm,amsfonts,amssymb,fancyhdr,graphicx,xcolor}
\usepackage{geometry}
\usepackage{enumerate}
\usepackage[style=authoryear, maxcitenames=1]{biblatex}
%\usepackage{minted}
\usepackage[most]{tcolorbox}

\addbibresource{citations.bib}
\geometry{letterpaper, margin=1in}

% For indicator functions:
\DeclareMathAlphabet{\mathmybb}{U}{bbold}{m}{n}
\newcommand{\1}{\mathmybb{1}}

%\newtcolorbox[auto counter, number within=section]{proposition}[2][Proposition]{%
%  colframe=blue!50!black,
%  colback=blue!10,
%  coltitle=white,
%  fonttitle=\bfseries,
%  title=#1~\thetcbcounter\ifx#2\empty\else~(#2)\fi}
%
%\newtcolorbox[auto counter, number within=section]{definition}{%
%  fonttitle=\bfseries,
%  title=Definition~\thetcbcounter,
%  label={def:\thetcbcounter}}

\newtcolorbox{myproofbox}{
  breakable,
  colback=white,
  colframe=black,
  boxrule=0.5pt,
  arc=0mm,
  left=1mm,
  right=1mm,
  top=1mm,
  bottom=1mm
}

\newtheorem{definition}{Definition}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{theorem}[proposition]{Theorem}
\newtheorem{corollary}[proposition]{Corollary}
\newtheorem{lemma}[proposition]{Lemma}

\DeclareMathOperator*{\argmin}{arg\,min}

\newcommand{\R}{\mathbb{R}}
\newcommand{\Borel}[1]{\mathcal{B}\paren{#1}}
\newcommand{\0}{\emptyset}
\newcommand{\prob}{\mathbb{P}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Ep}[1]{\mathbb{E}\left[ #1 \right]}
\newcommand{\paren}[1]{\left(#1 \right)}
\newcommand{\sqbr}[1]{\left[#1 \right]}
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\norm}[1]{|\hspace{-1pt}|#1 |\hspace{-1pt}|}
\newcommand{\normsq}[1]{\norm{#1}^{2}}
\newcommand{\ind}[1]{\mathmybb{1}_{\sqbr{#1}}}
\newcommand{\data}{\mathcal{D}_{n}}
\newcommand{\Hcal}{\mathcal{H}}
\newcommand{\Acal}{\mathcal{A}_{n}}
\newcommand{\Tcal}{\mathcal{T}_{n}}
\newcommand{\Ncal}{\mathcal{N}}
\newcommand{\Mcal}{\mathcal{M}}
\newcommand{\Fcal}{\mathcal{F}}
\newcommand{\aseq}{\stackrel{\mathrm{a.s.}}{=}}
\newcommand{\X}{\boldsymbol{X}}
\newcommand{\x}{\boldsymbol{x}}
\newcommand{\y}{\boldsymbol{y}}
\newcommand{\e}{\boldsymbol{e}}
\newcommand{\Cov}[1]{\mathrm{Cov}\paren{#1}}
\newcommand{\bbeta}{\boldsymbol{\beta}}
\newcommand{\bbetahat}{\boldsymbol{\hat{\beta}}}
\newcommand{\bepsilon}{\boldsymbol{\epsilon}}
\newcommand{\Loss}[1]{L_{n}\paren{#1}}
\newcommand{\Rhat}[2]{\hat{R}_{n, #1}\paren{#2}}
\newcommand{\alphahat}[1]{\hat{\alpha}^{#1}}
\newcommand{\alphatilde}{\tilde{\alpha}}
\newcommand{\alphabar}{\bar{\alpha}}
\newcommand{\lev}{h_{ii,\alpha}}
\newcommand{\loocv}[1]{\hat{R}^{(1)}_{n}\paren{#1}}
\newcommand{\ho}{\hat{L}_{\mathrm{ho}}}
\newcommand{\op}[1]{o_{\prob}\paren{#1}}
\newcommand{\Op}[1]{O_{\prob}\paren{#1}}
\newcommand{\sigmahat}{\hat{\sigma}^{2}_{n}}
\newcommand{\fhat}[2]{\hat{f}_{#1, #2}}
\newcommand{\ftilde}[1]{\tilde{f}_{#1}}
\newcommand{\lambdahat}[1]{\hat{\lambda}_{#1}}
\newcommand{\blambdahat}{\boldsymbol{\hat{\lambda}}}
\newcommand{\pen}[1]{\mathrm{pen}\paren{#1}}
\newcommand{\penBIC}[1]{\mathrm{pen}_{\mathrm{BIC}}\paren{#1}}
\newcommand{\tr}[1]{\mathrm{tr}\paren{#1}}
\newcommand{\ols}[1]{\paren{\X^{\top}_{#1}\X_{#1}}\X^{\top}_{#1}\y}
\newcommand{\fho}{\hat{f}^{(\mathrm{ho})}_{n}}

\title{MATH 410 Report: The Asymptotics of Cross-Validation and Aggregation in the Regression Setting}
\author{Diego Urdapilleta de la Parra}
\begin{document}

\maketitle
\tableofcontents

\newpage
\section{Introduction}

The goal of this project is to study the asymptotic properties of cross-validation (CV) methods for model selection in a variety of scenarios.~\textcolor{red}{[(\ldots) motivation, brief description of CV methods, outline of the project.]}

\subsection{The problem of model selection}
\begin{itemize}
    \item Computational complexity
    \item Statistical efficiency
    \item Prediction performance
    \item Assessing conditions
\end{itemize}

\subsection{Setup and notation}\label{sec:setup}

Throughout this report, we consider the following regression setup. For positive integers \(n\) and \(p_{n}\), let \((y, \x):\Omega\to\R\times[0,1]^{p_{n}}\) be a real-valued random vector with distribution \(\mu_{y, \x}\) such that \(\E{|y|^{2}}<\infty\), \(\E\normsq{\x}<\infty\), and \(\Ep{\x\x^{\top}}\succ 0\). A Borel-measurable function \(f:[0,1]^{p_{n}} \to \R\) that satisfies
\begin{equation}\label{eq:setup}
    f(\x) \aseq \Ep{y\mid \x}
\end{equation}
is called the \emph{regression} function of \(y\) on \(\x\).\footnote{Technically, it would be more accurate to refer to \emph{a version of} the regression function \(f\), since it is only unique in the almost-sure sense. In this report, however, we adopt the common convension of treating \(f\) as a single, well-defined function.}

We are treat \(y\) as a response and \(\x\) as a covariate vector, and we would like to estimate the regression function \(f\) from sampled data. To this end, suppose that we have a sample \(\data := \set{\paren{y_{i}, \x_{i}}:i\in [n]}\) of independent data points drawn from the distribution \(\mu_{y, \x}\). We define the residual \(\epsilon_{i}:= y_{i} - f(\x_{i})\), which yields the decomposition
\[y_{i} = f(\x_{i}) + \epsilon_{i}, \quad i\in[n].\]
In general, we will assume that the second moment \(\Ep{\epsilon^{2}_{i}\mid\x}\) is bounded almost surely. We may also abuse notation by writing
\[\y_{n} = f(\X_{n}) + \bepsilon_{n},\]
where  \(\y_{n}\) is the vector of responses, \(\bepsilon_{n}\) is the vector of residuals, \(\X_{n} = [\x_{1}^{\top}\;\cdots\;\x_{n}^{\top}]^{\top}\) denotes the design matrix, and \(f(\X_{n}) = (f(\x_{1}),\ldots,f(\x_{n}))\).

We will use the notation \(\norm{\cdot}\) to denote the Euclidean norm on \(\R^{n}\) (and, in some contexts, other finite-dimensional vector spaces on \(\R\)). At the same time, for \(q\geq 1\) and \(g\in L_{q}([0,1], \mathcal{B}[0,1], \mu_{\x})\), we write 
\[\norm{g}_{q} := \begin{cases}
    \paren{\int|g|^{q}\,d\mu_{\x}}^{1/q}&\text{if }1\leq q < \infty,\\[2mm]
    \sup\set{c\in\R:\mu_{\x}\set{|f|>c}>0} &\text{if } q = \infty,
\end{cases}\]
where \(\mathcal{B}[0,1]\) denotes the Borel \(\sigma\)-field over \([0,1]\) and \(\mu_{\x}\) denotes the marginal distribution of \(\x\).


\subsection{Cross-validation}



\newpage
\section{Variable Selection for Linear Models}\label{sec:lm}
\subsection{Setup}\label{sec:lmsetup}
In this section, the regression function \(f\) in (\ref{eq:setup}) is assumed to be linear, so that the data is generated from a linear model of the form
\[\y = \X\bbeta + \e\]
where \(\X = {[\x_{1}\;\x_{2}\;\cdots\;\x_{n}]}^{\top}\in\R^{n\times p_{n}}\) is the design matrix, \(\y = \sqbr{y_{1}\; y_{2}\;\cdots\; y_{n}}^{\top}\), and \(\e\) is a mean-zero random vector with \(\Cov{\e} = \sigma^{2}\boldsymbol{I}_{n}\).

In the context of linear models, the model selection procesure reduces to selecting a subset of covariates from a set of candidate covariates of size \(p_n\). This is also known as \emph{variable selection}. We remark that the number \(p_n\) may depend on \(n\), and some assumptions on the growth of \(p_n\) will be established later.

We let \(\Acal\subset2^{[p_{n}]}\) be a family of index sets representing candidate models. For \(\alpha\in\Acal\), we denote by \(p_{n}(\alpha)\) the cardinality of \(\alpha\) and consider the model given by
\[f_{\alpha}(\X) = \X_{\alpha}\bbeta_{\alpha},\]
where \(\X_{\alpha}\) is the sub-matrix of \(\X\) containing only the columns indexed by \(\alpha\), and \(\bbeta_{\alpha}\) is the coefficient vector containing only the entries indexed by \(\alpha\) in \(\bbeta\). To perform the regression task on these models, we utilize the \emph{Ordinary Least Squares} (OLS) estimator \(\bbetahat_{\alpha}\) of \(\bbeta_{\alpha}\), which is given by
\[\bbetahat_{\alpha} = \ols{\alpha}.\]

We will use the variable selection framework outlined by the following definitions:

\begin{enumerate}
    \item We say \(\alpha\in\Acal\) is \emph{correct} if \(\Ep{\y\mid\X}\aseq f_{\alpha}(\X)\), and we denote by \(\Tcal\) the set of correct models in \(\Acal\).
    \item We say \(\alpha\in\Acal\) is \emph{wrong} if it is not correct, and we denote by \(\Tcal^{c}\) the set of wrong models in \(\Acal\).
    \item We say \(\Acal\) is \emph{embedded} if there exists an enumeration \(\alpha_{1}, \alpha_{2}, \ldots, \alpha_{k}\) of all elements in \(\Acal\) such that \[\alpha_{1}\subset\alpha_{2}\subset\cdots\subset\alpha_{k}.\]
\end{enumerate}

Throughout this section, we will also use the notations \(H_{\alpha} = \X_{\alpha}\paren{\X_{\alpha}^{\top}\X_{\alpha}}\X_{\alpha}^{\top}\) for the hat matrix, \(M_{\alpha}:=I_{n}-H_{\alpha}\) for the anihilator matrix, and \(h_{ii,\alpha}:=\x_{i\alpha}^{\top}{(\X_{\alpha}^{\top}\X_{\alpha})}^{-1}\x_{i\alpha}\) for the \(i\)th leverage corresponding to \(\alpha\in\Acal\).

In order to select one model over another, we need some way to measure and compare the quality of their predictive ability. A natural approach is to consider the distance between their estimated mean outcomes and the true mean structure given by \(f\). We define th

\begin{definition}\label{def:loss}
    For \(\alpha\in\Acal\), let \(\bbetahat_{\alpha}\) be the OLS estimator of \(\bbeta_{\alpha}\) and \(\hat{f}_{\alpha}(\X):=\X_{\alpha}\bbetahat_{\alpha}\). We denote the average squared error of \(\hat{f}_{\alpha}\) by
    \[\Loss{\alpha}:=\frac{1}{n}\normsq{f(\X) - \hat{f}_{\alpha}\paren{\X}}.\]
    Additionally, we write
    \[R_{n}(\alpha):= \Ep{\Loss{\alpha}\mid\X}.\]
\end{definition}

The following conditions will be useful throughout our treatment of linear models:
\begin{align*}
    &\mathbf{H1:}\qquad \liminf_{n\to\infty} \frac{1}{n}\normsq{M_{\alpha}\X\bbeta}>0 \text{ almost surely for all }\alpha \in\Tcal^{c}.\\
    &\mathbf{H2:} \qquad \Ep{\normsq{\x}}<\infty.\\[2.5mm]
    &\mathbf{H3:}\qquad \lim_{n\to\infty}\max_{i\leq n}\,h_{ii,\alpha} \aseq 0 \text{ for all }\alpha \in\Acal.\\
    &\mathbf{H4:}\qquad \sum_{\alpha\in\Tcal^{c}}\frac{1}{\paren{nR_{n}(\alpha)}^{m}}\to_{\prob}0\text{ and }\Ep{e_i^{4m}\mid\x_i}<\infty\quad\text{for some }m\geq 1.
\end{align*}

Condition \textbf{H1} establishes a minimal difference in predictive ability between correct and wrong models. It ensures that the signal be strong enough that the distinction between correct and wrong matters. Indeed, if there is no meaningful difference in performance between the two sets, we need not to worry about selection.
\textbf{H2} and \textbf{H4} are moment conditions that will allow us to derive convergence and apply the law of large numbers to derive asymptotic results.
Finally, condition \textbf{H3} ensures that there are no overly-influential data points in the models. It will be utilized, for instance, to prove some asymptotic properties of the Leave-one-out loss estimator.

We now state two preliminary results the justify are choice of \(L_{n}\) and \(R_{n}\) for selection purposes. 

\begin{proposition}\label{prop:lossshao}
    Assuming the setup of Definition~\ref{def:loss}, the following equalities hold almost surely:
    \[\Loss{\alpha} = \frac{1}{n}\normsq{H_{\alpha}\e} + \frac{1}{n}\normsq{M_{\alpha}\X\bbeta}\quad\text{and}\quad R_{n}(\alpha) = \frac{1}{n}\sigma^{2}p_{n}(\alpha) + \frac{1}{n}\normsq{M_{\alpha}\X\bbeta}\]
    where \(H_{\alpha} = \X_{\alpha}\paren{\X_{\alpha}^{\top}\X_{\alpha}}^{-1}\X_{\alpha}^{\top}\) and \(M_{\alpha}= I_{n} - H_{\alpha}\).
\end{proposition}

\begin{myproofbox}
    \textit{Proof: }
    First, we have that
    \begin{align*}
        \normsq{f(\X) - \hat{f}_{\alpha}(\X)} &= \normsq{\X\bbeta - \X_{\alpha}\bbetahat_{\alpha}}\\
        &= \normsq{\X\bbeta - H_{\alpha}\paren{\X\bbeta + \e}}\\
        &= \normsq{M_{\alpha}\X\bbeta - H_{\alpha}\e}.
    \end{align*}
    Notice that \(M_{\alpha}\X\bbeta\) and \(H_{\alpha}\e\) are orthogonal:
    \[\e^{\top}H_{\alpha}M_{\alpha}\X\bbeta  = \e^{\top}H_{\alpha}\paren{I_{n} - H_{\alpha}}\X\bbeta = \e^{\top}H_{\alpha}\X\bbeta - \e^{\top}H_{\alpha}\X\bbeta = 0.\]
    Hence, the first part follows from the Pythagorean theorem.

    For the second part, we note that \[\Ep{\normsq{H_{\alpha}\e}\mid\X} \aseq \tr{\Ep{\normsq{H_{\alpha}\e}\mid\X}} \aseq \Ep{\tr{\normsq{H_{\alpha}\e}}\mid\X},\]
    so that
    \begin{align*}
        \Ep{\normsq{H_{\alpha}\e}\mid\X} &= \Ep{\tr{\e^{\top}H_{\alpha}\e}\mid\X}\\
        &= \Ep{\tr{\e\e^{\top}H_{\alpha}}\mid\X}\\
        &= \tr{\Ep{\e\e^{\top}\mid\X}H_{\alpha}}\\
        &= \sigma^2\tr{H_{\alpha}}\\
        &= \sigma^{2}p_{n}(\alpha),
    \end{align*}
    where \(p_{n}(\alpha)\) denotes the size of model \(\alpha\).\qed{}
\end{myproofbox}

\begin{proposition}\label{prop:Ropt}
    Suppose that that \(\Tcal\) is non-empty, and let \(\alpha^{*}_{n}\) be the smallest correct model in \(\Tcal\). Then, \(\alpha^{*}_{n}\) minimizes \(R_{n}(\alpha)\) over \(\alpha\in\Acal\) with probability 1.
\end{proposition}

\begin{myproofbox}
    \textit{Proof: }
    Let \(\alpha\in\Acal\) be arbitrary and suppose that \(\alpha\in\Tcal\). Then, \(\X_{\alpha}\bbeta_{\alpha} = \X\bbeta\) and \(p_{n}(\alpha_{n}^{*})\leq p_{n}(\alpha)\). Thus,
    \begin{align*}
        R_{n}(\alpha) &= \frac{1}{n}\sigma^{2}p_{n}(\alpha) + \frac{1}{n}\normsq{M_{\alpha}\X\bbeta}\\[2mm]
        &= \frac{1}{n} \sigma^{2}p_{n}(\alpha) + \frac{1}{n}\underbrace{\normsq{M_{\alpha}\X_{\alpha}\bbeta_{\alpha}}}_{0}\\
        &= \frac{1}{n}\sigma^{2}p_{n}(\alpha)\; \geq \; \frac{1}{n}\sigma^{2}p_{n}(\alpha_{n}^{*}) = R_{n}(\alpha_{n}^{*}).
    \end{align*}
    Now suppose that \(\alpha\in\Tcal^{c}\). If \(p_{n}(\alpha)\geq p_{n}(\alpha_{n}^{*})\), the result follows immediately by assumption H1. On the other hand, if \(p_{n}(\alpha)\leq p_{n}(\alpha_{n}^{*})\), we must verify that
    \begin{equation}\label{eq:Roptgoal}
        \normsq{M_{\alpha}\X\bbeta} \geq \sigma^{2}\paren{p_{n}(\alpha_{n}^{*}) - p_{n}(\alpha)}.
    \end{equation}
    To this end, we note that \(\normsq{M_{\alpha}\X\bbeta} = \normsq{M_{\alpha}\X_{\alpha_{n}^{*}}\bbeta_{\alpha_{n}^{*}}}\) and that 
    \[\X_{\alpha_{n}^{*}}\bbeta_{\alpha_{n}^{*}} = \X_{\alpha}\bbeta_{\alpha} + \X_{\alpha_{n}^{*}\setminus\alpha}\bbeta_{\alpha_{n}^{*}\setminus\alpha} .\]
    Thus, if we let \(\lambda\) denote the smallest eigenvalue of \(\X_{\alpha_{n}^{*}}^{\top}M_{\alpha}\X_{\alpha_{n}^{*}}\), we have that
    \[\normsq{M_{\alpha}\X\bbeta} = \normsq{M_{\alpha}\X_{\alpha_{n}^{*}\setminus\alpha}\bbeta_{\alpha_{n}^{*}\setminus\alpha}} \geq \lambda\normsq{\bbeta_{\alpha*\setminus\alpha}}\]
    (for a proof of the latter inequality, see~\textcite{hansen_2022}).
    \textcolor{red}{This is as far as I got. I don't know how to show that \(\lambda\normsq{\bbeta_{\alpha_{n}^{*}\setminus\alpha}}\geq \sigma^{2}\paren{p_{n}(\alpha_{n}^{*}) - p_{n}(\alpha)}\), but it seems reasonable if the coefficients in \(\bbeta\) are not too small.}\qed{}
\end{myproofbox}

From Proposition~\ref{prop:Ropt}, we see that \(R_{n}\) is an effective selection criterion. Unfortunately, \(R_{n}\) is an unkown expectation that depends on the regression function \(f\), and therefore cannot be used in practice. Instead, we may try to approximate it through some other empirically feasible criterion, \(\hat{R}_{n}\), which we treat as an ``estimator'' of the random quantity \(R_{n}\).

\begin{definition}\label{def:consistency97}
    Let \(\hat{R}_{n}\) be a model selection criterion and let \(\alphahat{}_{n}\) be the model selected by minimizing \(\hat{R}_{n}\) over \(\Acal\). Let \(\alpha^{*}_{n}\) denote the model minimizing \(R_{n}\) over \(\Acal\). We say that \(\hat{R}_{n}\) is {consistent} if 
    \[\prob\set{\alphahat{}_{n} = \alpha^{*}_{n}}\to 1\]
    as \(n\to\infty\). We say that \(\hat{R}_{n}\) is {assomptotically loss efficient} if 
    \[\frac{L_{n}(\alphahat{}_{n})}{L_{n}(\alpha^{*}_{n})}\xrightarrow{\prob} 1.\]
\end{definition}

Consistency as defined above is a naturally desirable property for any selection criterion \(\hat{R}_{n}\): it ensures that, asymptotically, \(\hat{R}_{n}\) will select the same model as the optimal risk \(R_{n}\). Asymptotic loss efficiency is a weaker property that captures a certain degree of ``closeness'' between \(\alphahat{}_{n}\) and \(\alpha^{*}_{n}\). All consistent criteria are asymptotically loss efficient:

\begin{lemma}\label{lemm:implication}
    If \(\hat{R}_{n}\) is consistent, then it is asymptotically loss efficient.
\end{lemma}

\begin{myproofbox}
    \textit{Proof: }
    Suppose that \(\hat{R}_{n}\) is consistent. Clearly, if \(\alphahat{}_{n} = \alpha^{*}_{n}\), then \(\Loss{\alphahat{}} = \Loss{\alpha^{*}_{n}}\). Therefore, 
    \[\prob\set{\alphahat{}_{n} = \alpha^{*}_{n}}\leq \prob\set{\Loss{\alphahat{}} = \Loss{\alpha^{*}_{n}}}.\]
    By consistency, the left-hand side converges to 1, so that the right-hand side must also converge to 1.\qed{}
\end{myproofbox}

The converse of Lemma~\ref{lemm:implication} is not necessarily true. However, since asymptotic loss efficiency is easier to prove than consistency, it is in our interest to find conditions for their equivalency. Proposition~\ref{prop:equiv} illustrates two such cases.

\begin{proposition}[\cite{shao_1997}]\label{prop:equiv}
    Suppose H1, \(p_{n}/n\to 0\), and that \(\Tcal\) is non-empty for all but finitely many \(n\).
    \begin{enumerate}
        \item If \(|\Tcal|=1\) for all but finitely many \(n\), then consistency is equivalent to efficiency in the sense of Definition~\ref{def:consistency97}.
        \item If \(p_{n}(\alpha^{*}_{n})\not\xrightarrow{\prob}\infty\), then consistency is equivalent to efficiency in the sense of Definition~\ref{def:consistency97}.
    \end{enumerate}
\end{proposition}
\begin{myproofbox}
    \textit{Proof: }
    From Lemma~\ref{lemm:implication}, it remains to show that, under the given conditions, asymptotic loss efficiency implies consistency. We show the contrapositive:

    \noindent1.\quad Suppose that \(\hat{R}_{n}\) is not consistent. By Proposition~\ref{prop:Ropt}, \(\alpha^{*}_{n}\) must be the correct model in \(\Tcal\) minimizing \(R_{n}\). Therefore, \(\Loss{\alpha^{*}_{n}} = (1/n)\normsq{H_{\alpha}\e}\), and
    \[\Ep{\Loss{\alpha^{*}_{n}}} = \frac{1}{n}\sigma^{2}p_{n}(\alpha^{*}_{n})\leq \frac{1}{n}\sigma^{2}p_{n}\to 0 \quad\text{as }n\to\infty\]
    by assumption. We have shown that \(\Loss{\alpha^{*}_{n}}\xrightarrow{L_{1}} 0\), which implies \(\Loss{\alpha^{*}_{n}}\xrightarrow{\prob} 0\).

    On the other hand, since \(\hat{R}_{n}\) is not consistent, there must exist \(\alphatilde_{n}\neq\alpha^{*}\) for infinitely many \(n\) such that \(\prob\set{\alphahat{}_{n} = \alphatilde_{n}} \neq 0\). Notice that, since \(\Tcal=\set{\alpha^{*}}\), it must be the case that \(\alphatilde_{n}\in\Tcal^{c}\). We have the following:
    \[\Loss{\alphahat{}_{n}}\geq \ind{\alphahat{}_{n} = \alphatilde_{n}}\Loss{\alphatilde_{n}} = \ind{\alphahat{}_{n} = \alphatilde_{n}}\paren{\frac{1}{n}\normsq{H_{\alphatilde_{n}}\e + \frac{1}{n}\normsq{M_{\alpha}\X\bbeta}}}.\]
    By assumption \textbf{H1}, the latter expression cannot not converge to 0. We conclude that the ratio \(\Loss{\alphahat{}_{n}}/\Loss{\alpha^{*}}\not\xrightarrow{\prob} 1\).

    \noindent2.\quad Suppose again that \(\hat{R}_{n}\) is not consistent. Since \(\Tcal\) contains at least two models, there must exist \(\alphatilde_{n}\in\Tcal\) such that \(\alphatilde_{n}\neq \alpha^{*}\) and \(\prob\set{\alphahat{}_{n} = \alphatilde_{n}}\not\to 0\). Hence,
    \[\frac{\Loss{\alphahat{}_{n}}}{\Loss{\alpha^{*}_{n}}} - 1 \geq \paren{\frac{\Loss{\alphatilde{}_{n}}}{\Loss{\alpha^{*}_{n}}} - 1}\ind{\alphahat{}_{n} = \alphatilde_{n}} = \paren{\frac{\normsq{H_{\alphatilde_{n}}}}{\normsq{H_{\alpha^{*}_{n}}}} - 1}\ind{\alphahat{}_{n} = \alphatilde_{n}}\not\xrightarrow{\prob}0.\]\qed{}
\end{myproofbox}

\subsection{A result on the leave-one-out}\label{sec:loo}
\renewcommand{\Acal}{\mathcal{A}}
\renewcommand{\Tcal}{\mathcal{T}}

Having established some essential results in the previous section, we now turn our attention to a particular variant of cross-validation, namely the leave-one-out. For this section, we will only consider the case where the set \(\Acal_{n}=:\Acal\) and all its elemets are constant across all \(n\geq 1\). That is, the candidate models are not changed by the number of observations.

The leave-one-out cross-validation method (otherwise known as delete-1 CV) consists in estimating a model using the data with one point removed, and then evaluating our estimate on the single removed point. This procedure is repeated for each data point and the results are averaged out onto a single loss estimate \(\loocv{\alpha}\) of \(R_{n}(\alpha)\). Formally, we define the leave-one-out loss estimator for a model \(\alpha\in\Acal\) to be 
\[\loocv{\alpha} := \frac{1}{n}\sum_{i=1}^{n}\paren{(y_{i} - \x_{i\alpha}^{\top}\bbetahat_{\alpha}^{(i)})}\qquad\text{with }\bbetahat_{\alpha}^{(i)} = \paren{\sum_{i\in[n]\setminus\set{i}}\x_{i\alpha}\x_{i\alpha}^{\top}}^{-1} \sum_{i\in[n]\setminus\set{i}} y_{i}\x_{i\alpha}.\]
The leave-one-out is a very popular tool for linear models due to its low computational cost. The following proposition shows that it is not necessary to fit all \(n\) coefficient vectors \(\bbetahat_{\alpha}^{(i)}\): it suffices to fit the model on the complete dataset just once. The proof uses the Sherman-Morrison inversion formula and will not be presented here.

\begin{proposition}
    For \(alpha\in\Acal\), the leave-one-out estimator \(\loocv{\alpha}\) satisfies the following equality:
    \[\loocv{\alpha}= \frac{1}{n}\sum_{i=1}^{n}\paren{\frac{y_{i}-\x_{i\alpha}^{\top}\bbetahat_{\alpha}}{1-h_{ii,\alpha}}}^{2},\]
    where \(h_{ii,\alpha} = \x_{i\alpha}^{\top}{(\X_{\alpha}^{\top}\X_{\alpha})}^{-1}\x_{i\alpha}\) denotes the \(i\)th leverage and \(\bbetahat_{\alpha}\) is the OLS estimator for model \(\alpha\) fitted on the whole data set.
\end{proposition}

Our goal in this section is to show some asymptotic properties of the leave-one-out as a criterion for model selection. The main result,~\ref{prop:shao93main} below, uses the following decomposition of \(\loocv{\alpha}\) in terms of \(R_{n}\) and other familiar quanitities.

\begin{lemma}[\cite{shao_1993}]\label{lem:lemmadecomp}
    \begin{equation}\label{eq:lemmadecomp}
    \loocv{\alpha} = \begin{cases}
        R_{n}(\alpha) + \sigma^{2} + \op{1} &\text{ if }\alpha\in\Tcal^{c}\\[2mm]
        \frac{1}{n}\normsq{M_{\alpha}\e} + \frac{2}{n}\sigma^{2}p(\alpha) + \op{n^{-1}} &\text{ if }\alpha\in\Tcal
    \end{cases}
    \end{equation}
\end{lemma}

\begin{myproofbox}
    \textit{Proof: }
    Using the Taylor expansion of \(1/{(1-x)}^{2} = 1+2x + O(x^{2})\), we have
    \[\frac{1}{\paren{1-\lev}^{2}} = 1 + 2\lev + \Op{\lev^{2}}.\]
    Thus,
    \begin{equation}
        \label{eq:xizeta}
        \loocv{\alpha} = \underbrace{\frac{1}{n}\sum_{i=1}^{n}\paren{y_{i}-\x_{i\alpha}^{\top}\bbetahat_{\alpha}}^{2}}_{\xi_{\alpha,n}} + \underbrace{\frac{1}{n}\sum_{i=1}^{n}\paren{2\lev + \Op{\lev^{2}}}\paren{y_{i}-\x_{i\alpha}^{\top}\bbetahat_{\alpha}}^{2}}_{\zeta_{\alpha,n}}
    \end{equation}
    Let \(\xi_{\alpha,n}\) and \(\zeta_{\alpha,n}\) denote the first and second terms in (\ref{eq:xizeta}), respectively. Note that
    \begin{align}
        \notag\xi_{\alpha,n} &= \frac{1}{n}\normsq{M_{\alpha}\X\bbeta + M_{\alpha}\e}\\
        \label{line:decomp}&= \frac{1}{n}\paren{\normsq{M_{\alpha}\e} + \normsq{M_{\alpha}\X\bbeta} + 2 \e^{\top}M_{\alpha}\X\bbeta}\\
        \label{line:decomp2}&=\frac{1}{n}\normsq{\e} + \frac{1}{n}\normsq{M_{\alpha}\X\bbeta} + \frac{1}{n}\normsq{H_{\alpha}\e} + \frac{2}{n}\e^{\top}M_{\alpha}\X\bbeta
        %\label{line:op1}&= \frac{1}{n}\normsq{\e} + \frac{1}{n}\normsq{M_{\alpha}\X\bbeta} + \op{1}.
    \end{align}
    From here, we emphasize four intermediate steps:
    \begin{enumerate}[i.]
        \item Using Markov's inequality, for \(\varepsilon>0\), \[\prob\set{\normsq{H_{\alpha}\e}\geq n\varepsilon}\leq \frac{\sigma^{2}p_{n}(\alpha)}{n\varepsilon}\to 0\] 
        \[\implies \frac{1}{n}\normsq{H_{\alpha}\e} = o_{\prob}(1).\]
        \item Since \(M_{\alpha}\) is a projection matrix, \(\normsq{M_{\alpha}\X\bbeta}\leq \normsq{\X\bbeta} = O_{\prob}(n)\), so that \[\Ep{\paren{\e^{\top} M_{\alpha}\X\bbeta}^{2}\mid\X} = \frac{4}{n^{2}}\sigma^{2}\normsq{M_{\alpha}\X\bbeta} = o_{\prob}(1).\] Combining the latter with \(\Ep{\e^{\top} M_{\alpha}\X\bbeta\mid\X} = 0\), we obtain that \[\frac{2}{n}\e^{\top}M_{\alpha}\X\bbeta = o_{\prob}(1).\]
        \item Combining i.\ and ii.\ with (\ref{line:decomp2}) yields \[\xi_{\alpha,n} = \frac{1}{n}\normsq{\e} + \frac{1}{n}\normsq{M_{\alpha}\X\bbeta} + o_{\prob}(1).\] Furthermore, since \(\normsq{\e} = O_{\prob}(n)\), we have that \(\xi_{\alpha,n} = O_{\prob}(1)\).
        \item Finally, since \(0<\lev<1\), \(2\lev + \Op{\lev^{2}}\leq\Op{\max_{i}\lev}\). Thus,
        \[\zeta_{\alpha,n}\leq\Op{\max_{i}\lev}\paren{\frac{1}{n}\sum_{i=1}^{n}\paren{y_{i} - \x_{i\alpha}^{\top}\bbetahat_{\alpha}}^{2}} = \Op{\max_{i}\lev}\xi_{\alpha,n}.\]
        From assumption \textbf{H3}, \(\zeta_{\alpha,n} = o_{\prob}(1)\xi_{\alpha,n} = o_{\prob}(1)\).
    \end{enumerate}
    It follows that 
    \[\loocv{\alpha} = \frac{1}{n}\normsq{e} + \frac{1}{n}\normsq{M_{\alpha}\X\bbeta} + o_{\prob}(1) \stackrel{(\mathrm{LLN})}{=} \sigma^{2} + \frac{1}{n}\normsq{M_{\alpha}\X\bbeta} + o_{\prob}(1).\]
    Noting that \(R_{n}(\alpha) = \frac{1}{n}\normsq{M_{\alpha}\X\bbeta} + o_{\prob}(1)\) yields the first case in (\ref{eq:lemmadecomp}).

    If \(\alpha\in\Tcal\), it is easy to see from (\ref{line:decomp}) that \(\xi_{\alpha,n} = 1/n\normsq{M_{\alpha}\e}\), Furthermore,
    \[\zeta_{\alpha,n} = \frac{2}{n}\sigma^{2}p(\alpha) + \op{1},\qquad\textcolor{red}{(?)}\]
    proving the second case.\qed{}
\end{myproofbox}

\begin{proposition}[\cite{shao_1993}]\label{prop:shao93main}
    Suppose that \(\Tcal\) is non-empty and let \(\alphahat{(1)}\) be the model minimizing \(\loocv{\alpha}\).
    \begin{enumerate}
        \item Under H1, H2, and H3, \[\lim_{n\to\infty}\prob\set{\alphahat{(1)}\in\Tcal^{c}}=0.\]
        \item For \(\alpha\in\Tcal\) with \(\alpha\neq\alpha^{*}\),\[\prob\set{\loocv{\alpha}\leq \loocv{\alpha^{*}}} = \prob\set{2\paren{p(\alpha) - p(\alpha^{*})}\sigma^{2} < \e^{\top}(H_{\alpha} - H_{\alpha^{*}})\e} + \op{1}.\] In particular, if \(\e\sim\Ncal(0_{n}, \sigma^{2}I_n)\), \[\prob\set{\loocv{\alpha}\leq \loocv{\alpha^{*}}} = \prob\set{2k < \chi^{2}(k)} + \op{1} > 0\] for \(k=p(\alpha) - p(\alpha^{*})\).
        \item If \(p(\alpha^*) < p\), \[\lim_{n\to\infty}\prob\set{\alphahat{(1)}=\alpha^{*}}\neq 1.\]
    \end{enumerate}
\end{proposition}

Before continuing with the proof, a few comments are in order. The first part of the proposition shows that, under the given conditions, the leave-one-out will select a correct model with probability approaching 1 as \(n\) approaches infinity. This is a relatively strong result, as it implies that the leave-one-out is reliable at excluding wrong models. However, parts 2 and 3 tell us that the leave-one-out is not consistent for selection in the sense of Definition~\ref{def:consistency97}: it selects overly complex correct models with non-vanishing probability. In other words, the leave-one-out is prone to overfitting.

One heuristic explanation for this behavior, as noted by~\textcite{shao_1993}, is that the leave-one-out places too much weight on the estimation and too little on the evaluation. If we let \(n_{1}\) denote the size of the fitting sets and \(n_{2}:=1-n_{1}\) the size of the validation sets, from~\ref{lem:lemmadecomp} we have that \(R_{n_{1}}(\alpha) = \sigma^{2}p(\alpha)/n_{1}\) for any correct model \(\alpha\in\Tcal\). Clearly, optimizing \(R_{n_{1}}(\alpha)\) over \(\Tcal\) becomes difficult for large \(n_{1}\): the larger \(n_{1}\), the closer \(R_{n_{1}}(\alpha)\) is to a flat line. With the leave-one-out, we are choosing the largest possible \(n_{1}= n-1\), making is difficult for the estimator to distinguish between correct models.

\begin{myproofbox}
    \textit{Proof of Proposition~\ref{prop:shao93main}: }

    \noindent1.\quad Let \(\alphabar\in \Tcal\) and \(\alphatilde\in\Tcal^{c}\). By, Lemma~\ref{lem:lemmadecomp}, we have that
    \begin{align*}
        \prob&\set{\loocv{\alphatilde}\leq \loocv{\alphabar}}\\
        &\qquad = \prob\Big\{\frac{1}{n}\sigma^{2}p(\alphatilde) + \frac{1}{n}\normsq{M_{\alphatilde}\X\bbeta} + \sigma^{2} + o_{\prob}(1) \leq \frac{1}{n}\normsq{M_{\alphabar}\e} + \frac{1}{n}\sigma^{2}p(\alphabar) + o_{\prob}(n^{-1})\Big\}\\
        &\qquad= \prob\set{\frac{1}{n}\sigma^{2}\paren{p(\alphatilde) - p(\alphabar)} + \sigma^{2} + \frac{1}{n}\normsq{M_{\alphatilde}\X\bbeta} - \frac{1}{n}\normsq{M_{\alphabar}\e}\leq o_{\prob}(1)}.
    \end{align*}
    From \textbf{H1}, the latter probability goes to zero as \(n\to\infty\). Therefore, \(\ind{\loocv{\alphatilde}\leq \loocv{\alphabar}} = o_{p}(1)\). We now observe that
    \[\prob\set{\alphahat{(1)}\in\Tcal^{c}} = \Ep{\ind{[\alphahat{(1)}\in\Tcal^{c}]}} = \Ep{\sum_{\alphatilde\in\Tcal^{c}}\prod_{\alpha\in\Acal} \ind{\loocv{\alphatilde}\leq \loocv{\alpha}}} \to 0.\]

    \noindent2.\quad The first part follows from Lemma 2.1 by algebraic manipulation. The second part follows by noting that, if \(\e\sim\Ncal(0_{n}, \sigma^{2}I_{n})\), then \[\frac{\e^{\top}}{\sigma}\paren{H_{\alpha} - H_{\alpha^{*}}}\frac{\e}{\sigma}\sim\chi^{2}\paren{\mathrm{tr}\paren{H_{\alpha}-H_{\alpha^{*}}}}.\]

    \noindent3.\quad It is easy to see that \(p(\alpha^{*}) = p\) if and only if \(\Tcal=\set{\alpha^{*}}\). Thus, if \(p(\alpha^{*}) < p\), there exists \(\alpha\in\Tcal^{c}\) with \(\alpha\neq \alpha^{*}\). The result then follows by part 2 above.\qed{}
\end{myproofbox}

%A subsequent result states that cross-validation is consistent if \(n_{v}/n\to 1\) as \(n\to\infty\), where \(n_{v}\) is the number of validation samples.



\subsection[A general perspective]{A General Perspective \protect\footnote{For this section, we allow the set of candidates \(\Acal\) to vary with \(n\), though we assume that it remains finite. To illustrate why this might be useful, we consider an example drawn from~\textcite{shao_1997}:\\ \indent If we wish to approximate a univariate regression function \(x\mapsto f(x)\) by a polynomial of degree at most \(p_{n}< n\), we may consider the models indexed by \(\Acal:=\set{\alpha_{d}:d\in[p_n]}\), with \(\alpha_{d} = \set{1,\ldots,d}\) and \(f_{\alpha_{d}}(x) = \beta_{0} + \beta_{1}x + \cdots + \beta_{d}x^{d}\). Clearly, the number of candidate models increases as more observations become available. Furthermore, the dimension of the optimal model \(\alpha^{*}_{n}\), for instance, may also increase with \(n\).}}\label{sec:gic}
\renewcommand{\Acal}{\mathcal{A}_{n}}
\renewcommand{\Tcal}{\mathcal{T}_{n}}

Our previous observations suggest that a smaller estimation set and a larger validation set might improve the performance of cross-validation procedures for model selection. In this section, we explore this idea from a different perspective, understanding cross-validation as a special case of a more general approach to loss estimation.

In the context of selection, overfitting occurs because our choice of empirical loss may underestimate the true loss for large models. The inclusion of irrelevant information can make the estimator \(\hat{R}_{n}\) ``hallucinate'' a signal that is not there. To avoid this problem, we may use \emph{penalization}: we modify our estimator \(\hat{R}_{n}\) to favour the choice of less complex models. Given some loss estimator \(\hat{R}_{n}\), we may define the corresponding \emph{penalized selection criterion} as
\[\hat{R}_{n}'(\alpha) = \hat{R}_{n}(\alpha) + \pen{\alpha}\]
for some penalty function \(\mathrm{pen}:\Acal\to\R\). 

A large portion of selection criteria in the literature can be reduced to a general penalized criterion with a penalty given by 
\[\mathrm{pen}_{\lambda_{n}}(\alpha) = \frac{1}{n} \lambda_{n} \sigmahat p_{n}(\alpha),\]
for some some estimator \(\sigmahat\) of \(\sigma^{2}\) and a sequence of real numbers \(\set{\lambda_{n}}_{n\geq 1}\) satisfying certain conditions. This type of penalty, along with a standard \(L_{2}\) risk estimator, yields the \emph{Generalized Information Criterion}~(\cite{shao_1997}), defined below.

\begin{definition}\label{def:gic}
    We define the Generalized Informaton Criterion (GIC) loss estimator to be
    \[\Rhat{\lambda_{n}}{\alpha} := \frac{1}{n}\normsq{\y - \X_{\alpha}\bbetahat_{\alpha}} + \frac{1}{n}\lambda_{n}\sigmahat p_{n}(\alpha)\quad\text{for }\alpha\in\Acal,\]
    where \(\sigmahat\) is an estimator of \(\sigma^{2}\) and \(\lambda_{n}\) is a sequence of positive real numbers satisfying \(\lambda_{n}\geq 2\) and \(\lambda_{n}/n\to 0\).
\end{definition}

In what follows, we study some asymptotic properties of the GIC in two cases of interest: a constant \(\lambda_{n}\equiv 2\) and a growing \(\lambda_{n}\to\infty\).

\subsubsection{The case of \(\lambda_{n} \equiv 2\)}

\begin{theorem}[\cite{shao_1997}]\label{thm:97thm1}
    Suppose that \textbf{H4} holds and that \(\sigmahat\) is consistent for \(\sigma^{2}\). Let 
    \begin{enumerate}
        \item If \(|\Tcal|\leq1\) for all but finitely many \(n\), then \(\hat{R}_{n,2}\) is asymptotically loss efficient.
        \item Suppose that \(|\Tcal|> 1\) for all but finitely many \(n\). If there exists a positive integer \(m\) such that \(\Ep{y_{1} - \x_{1}^{\top}\bbeta}^{4m}<\infty\) and 
        \begin{equation}\label{eq:conditionsums}
            \sum_{\alpha\in\Tcal}\frac{1}{\paren{p_{n}(\alpha)}^{m}}\xrightarrow{n\to\infty} 0 \quad\text{or}\quad \sum_{\substack{\alpha\in\Tcal,\\ \alpha\neq\alpha^{*}}}\frac{1}{\paren{p_{n}(\alpha) - p_{n}(\alpha^{*})}^{m}}\xrightarrow{n\to\infty} 0,
        \end{equation}
        then \(\hat{R}_{n,2}\) is asymptotically loss efficient.
        \item Suppose that \(|\Tcal|>1\) for all but finitely many \(n\). 
        %Suppose, furthermore, that for any integer \(q\geq1\) and constant \(c>2\), 
        %\begin{equation}
        %    \label{eq:conditionQ}
        %    \liminf_{n\to\infty}\inf_{Q_{n}\in\mathcal{Q}_{n,q}}\prob\set{\normsq{Q_{n}\e} > c\sigma^{2}q} > 0,
        %\end{equation}
        %where \(\mathcal{Q}_{n,q}\) is the set of all projection matrices of rank \(q\). 
        If \(|\Tcal|\) is bounded,
        %or \(\Acal\) is embedded,
        then the condition that
        \begin{equation}
            \label{eq:conditionP}
            p_{n}(\alpha^{*}_{n})\to\infty\quad\text{or}\quad \min_{\substack{\alpha\in\Tcal,\\ \alpha\neq\alpha^{*}}}\paren{p_{n}(\alpha) - p_{n}(\alpha^{*})}\to\infty
        \end{equation}
        is necessary and sufficient for the asymptotic loss efficiency of \(\hat{R}_{n,2}\).
    \end{enumerate}
\end{theorem}

In short, Theorem~\ref{thm:97thm1} guarantees the asymptotic loss efficiency of \(\hat{R}_{n,2}\) in some cases where there exists at most one correct model with fixed dimension. In particular, the first part shows that \(\hat{R}_{n,2}\) asymptotically chooses the best-performing wrong model in the case that no correct model exists. If only one correct model exists in \(\Tcal\) and it has fixed dimension for all but finitely many \(n\), an application of Proposition~\ref{prop:equiv} in section~{\ref{sec:lmsetup}} yields consistency in selection. In other words, \(\hat{R}_{n,2}\) is able to identify the correct model among a set of incorrect models with probability tending to 1.

Parts 2.\ and 3.\ specify conditions for asymptotic loss efficiency in when multiple correct model exist. In these cases, \(\hat{R}_{n,2}\) performs well if no two correct models have fixed dimension. This is what conditions (\ref{eq:conditionsums}) and (\ref{eq:conditionP}) imply: they require that the dimensions of the models in \(\Tcal\) diverge, either absolutely or relative to \(\alpha^{*}\). The following example illustrates this phenomenon:

\begin{myproofbox}
    \textbf{Example:} Suppose that \(\Acal = \Tcal = \set{\alpha_{1n}, \alpha_{2n}}\) with \(\alpha_{1n}\subset\alpha_{2n}\). Note that 
    \[\normsq{\y - \X_{\alpha}\bbetahat_{\alpha}} = \normsq{\e} - \normsq{H_{\alpha}\e}.\]
    Then, form Definition~\ref{def:gic}, \(\alphahat{}_{n} = \alpha_{1n}\) if and only if
    \begin{equation}\label{eq:examplecrit}
    \normsq{H_{\alpha_{2n}} - H_{\alpha_{1n}}\e} < 2\sigmahat\paren{p_{2n}-p_{1n}},
    \end{equation}
    where \(p_{1n}\) and \(p_{2n}\) denote the dimensions of \(\alpha_{1n}\) and \(\alpha_{2n}\), respectively. If \(p_{1n}\to\infty\) and \(p_{2n} - p_{1n}\to\infty\), then
    \[\frac{\normsq{\paren{H_{\alpha_{2n}} - H_{\alpha_{1n}}}\e}}{p_{2n} - p_{1n}}\xrightarrow{\prob}\sigma^{2},\]
    so that (\ref{eq:examplecrit}) is satisfied with probability approaching 1 (by consistency of \(\sigmahat\)), and \(\Rhat{2}{\alpha}\) is consistent. If \(p_{1n}\to\infty\) but \(p_{2n} - p_{1n}\leq c\) for some \(c>0\), then \(p_{2n} / p_{1n}\to 1\), which yields \(\Loss{\alpha_{2n}}/\Loss{\alpha_{1n}} \to 1\). On the other hand, if \(\alpha_{1n}\) and \(p_{2n} - p_{1n}\not\to\infty\), then
    \[\frac{\Loss{\alphahat{}_{n}}}{\Loss{\alpha_{1n}}} = \ind{\alphahat{}_{n}=\alpha_{1n}} + \frac{\normsq{H_{\alpha_{2n}}\e}}{\normsq{H_{\alpha_{2n}}\e}}\ind{\alphahat{}_{n}=\alpha_{1n}}\]
    (see Prop.~\ref{prop:lossshao}). By Proposition~\ref{prop:Ropt}, \({\normsq{H_{\alpha_{2n}}\e}}/{\normsq{H_{\alpha_{2n}}\e}}\geq\) almost surely. Hence,
    \[\frac{\Loss{\alphahat{}_{n}}}{\Loss{\alpha_{1n}}} = 1 + \paren{\frac{\normsq{H_{\alpha_{2n}}\e}}{\normsq{H_{\alpha_{2n}}\e}} - 1}\ind{\alphahat{}_{n}=\alpha_{1n}} = 1 + \frac{\normsq{\paren{H_{\alpha_{2n}} - H_{\alpha_{1n}}}\e}}{\normsq{H_{\alpha_{2n}}\e}} \stackrel{\mathrm{a.s.}}{>} 1.\]
    Thus, \(\Rhat{2}{\alpha}\) is not asymptotically loss efficient.    
\end{myproofbox}


%Note that condition (\ref{eq:conditionQ}) is satisfied if \(\e\sim\Ncal(0_{n}, \sigma^{2}I_{n})\). Condition (\ref{eq:conditionP}) is satisfied if \(\Acal\) does not contain two correct models with fixed dimension for all but finitely many \(n\).

Notice that these results resemble those presented in section~{\ref{sec:loo}} about the leave-one-out cross-validation estimator. Indeed, the correspondance between the leave-one-out and the GIC with \(\lambda_{n}\equiv 2\) will be discussed in section~{\ref{sec:gicdisc}}.

The proof of Theorem~\ref{thm:97thm1} uses the following decomposition, which we state without proof.

\begin{proposition}[\cite{shao_1997}]\label{prop:97decomp1}
    Suppose that \(\lambda_{n}=2\) for all \(n\geq 1\) and that \(\sigmahat\) is a consistent estimator of \(\sigma^{2}\). Then,
    \[\Rhat{2}{\alpha} = \begin{cases}
        \frac{1}{n}\normsq{e} + \frac{2}{n}\sigmahat p_{n}(\alpha) - \frac{1}{n}\normsq{H_{\alpha}\e}, &\text{if }\alpha\in\Tcal,\\[3mm]
        \frac{1}{n}\normsq{e} + \Loss{\alpha} + \op{\Loss{\alpha}}, &\text{if }\alpha\in\Tcal^{c}.
    \end{cases}\]
\end{proposition}

\begin{myproofbox}
    \textit{Proof of Theorem~\ref{thm:97thm1}: }

    \noindent1.\quad That \(\hat{R}_{n,2}\) satisfies asymptotic loss efficiency when \(\Tcal\) is empty follows immediately from Proposition~\ref{prop:97decomp1}. If \(Tcal\) contains exactly one model \(\alpha^{*}\), \textcolor{red}{the proof for this is given in the last paragraph of page 226. I don't understand it.}
    
    \noindent2.\quad 

    \qed{}
\end{myproofbox}

\subsubsection{The case of \(\lambda_{n} \to \infty\)}

We now consider the GIC \(\hat{R}_{n,\lambda_{n}}\) with \(\lambda_{n}\to\infty\) as \(n\to \infty\). Unlike in the previous section, the following results do not require that \(\sigmahat\) be consistent for \(\sigma^{2}\).

\begin{theorem}[\cite{shao_1997}]\label{thm:97thm2}
    Suppose that \textbf{H4} holds and that
    \begin{equation}\label{eq:310}
        \limsup_{n\to\infty}\sum_{\alpha\in\Tcal}\frac{1}{p_{n}{(\alpha)}^{m}}<\infty
    \end{equation}
    for some \(m\geq1\) with \(\Ep{e_{i}^{4m}}<\infty\).
    \begin{enumerate}
        \item If \textbf{H1}, \(\lambda_{n}\to\infty\), and \(\lambda_{n}p_{n}/n \to 0\) are satisfied, then \(\hat{R}_{n,\lambda_{n}}\) is asymptotically loss efficient.
        \item If there exists \(\alpha_{0}\in\Tcal\) with \(p_{n}(\alpha_{0})\) constant for all but finitely many \(n\), \(\lambda_{n}\to\infty\), and \(\lambda_{n}/n\to 0\), then \(\hat{R}_{n,\lambda_{n}}\) is consistent. 
    \end{enumerate}
\end{theorem}



\textbf{Remark:} Condition (\ref{eq:310}) is satisfied whenever \(|\Tcal|\) is bounded or \(\Acal\) is embedded. It implies that 
\[ \max_{\alpha\in\Tcal} \frac{\normsq{H_{\alpha}\e}}{\lambda_{n}\sigmahat p_{n}(\alpha)}\xrightarrow{\prob} 0.\]

As in the case of Theorem~\ref{thm:97thm1}, the proof of Theorem~\ref{thm:97thm2} relies on a decomposition that we state without proof.

\begin{proposition}[\cite{shao_1997}]\label{prop:97decomp2}
    Suppose that \(\lambda_{n}=2\) for all \(n\geq 1\) and that \(\sigmahat\) is a consistent estimator of \(\sigma^{2}\). Then,
    \[\Rhat{2}{\alpha} = \begin{cases}
        \frac{1}{n}\normsq{\e} + \frac{2}{n}\sigmahat p_{n}(\alpha) - \frac{1}{n}\normsq{H_{\alpha}\e} &\text{if }\alpha\in\Tcal\\[3mm]
        \frac{1}{n}\normsq{\e} + \Loss{\alpha} + \frac{1}{n}p_{n}(\lambda_{n}\sigmahat - 2\sigma^{2}) + \op{\Loss{\alpha}} &\text{if }\alpha\in\Tcal^{c}
    \end{cases}\]
\end{proposition}

\subsubsection{Cross-validation and the GIC}

\begin{theorem}[\cite{shao_1997}]\label{thm:97thm45}
    \( \)

    \begin{enumerate}
        \item If \textbf{H3} holds, then Theorem~\ref{thm:97thm1} applies for the leave-one-out estimator.
        \item Suppose that \textbf{H1}, \textbf{H4}, and (\ref{eq:310}) hold. If the splits are ``balanced'', and \(d\) is chosen so that \(d/n\to1\) and \(p_n/(n-d) \to 0\), then the delete-\(d\) cross-validation estimator is asymptotically loss efficient 
    \end{enumerate}
\end{theorem}

\textcolor{red}{MISSING: Discussion.}


\section{Selection of Nonparametric Procedures}

\subsection{Setup}

In statistical learning, we are oftentimes more interested in finding a practical means for prediction rather than a precise description of the data-generating mechanism. In these cases, where the goal is optimal predictive performance, the notion of a ``true'' or ``correct'' model becomes less meaningful. Indeed, for many kinds of nonparametric estimators, it is possible to establish inequalities of the form
%\footnote{Here, \(\norm{\cdot}_{2}\) denotes the \(L_{2}[0,1]\) norm given by \(\norm{f}_{2} = \paren{\int |f|^{2}\,d\lambda}^{1/2}\).}
\[\sup_{f\in\Fcal}\E{\normsq{f - \hat{f}_{n}}} \leq C\psi_{n}^{2}\]
for certain constants \(C\), positive sequences \(\psi_{n}\to 0\), and classes of functions \(\Fcal\) (see~\cite{tsybakov_introduction_2009}). These inequalities imply that the risk is guaranteed to approach 0 as n increases, and therefore, unlike in linear models, model specification is less of a concern (although the inclusion of relevant covariates remains relevant). 

The problem of selecting a nonparametric estimator of the regression function, then, focuses more on the rates of convergence \(\psi_{n}\) of each procedure. In this section, we will consider the simplified scenario of selecting between 
two regression procedures, denoted \(\delta_{1}\) and \(\delta_{2}\), that yield estimators \(\hat{f}_{n, 1}\) and \(\hat{f}_{n, 2}\) of the regression function \(f\).

\begin{definition}
    Let \(L_{n}\) be a loss function. We say \(\delta_{1}\) is \emph{asymptotically better} than \(\delta_{2}\) under \(L_{n}\) if, for \(0<\varepsilon<1\), there exists \(c_{\varepsilon}>0\) such that
    \[\prob\set{\Loss{\fhat{n}{2}}\geq (1+c_{\epsilon})\Loss{\fhat{n}{2}} }\geq 1-\varepsilon\]
    for all but finitely many \(n\).

    Given that \(\delta_{1}\) is asymptotically better than \(\delta_{2}\), we say that a selection procedure is consistent if it selects \(\delta_{1}\) with probability tending to 1 as \(n\to\infty\).
\end{definition}

In what follows, we will study the asymptotic performance of two variations on the cross-validation method for selecting an estimator. First, we will show that cross-validation with a single data split, also known as the \emph{hold-out}, is consistent in selection under some conditions on how the split is performed. Afterwards, we will show that this result extends to the multiple-split case with majority vote.

\subsection{Single-split cross-validation (the \emph{hold-out})}

For this section, we analyze a single-split approach where the first \(n_1\) elements in \(\data\) are used as a training/estimation sample and the remaining \(n_2\) elements make up the validation sample. We assume that the estimators \(\fhat{n}{1}\) and \(\fhat{n}{2}\) converge exactly at rates \(\set{p_{n}}_{n\geq 1}\) and \(\set{q_{n}}_{n\geq 1}\) under the \(L_{2}[0,1]\) loss, respectively. In other words, we assume that
\[\norm{f, \fhat{n}{1}}_{2} = \Op{p_{n}} \quad\text{and}\quad \prob\set{\norm{f-\fhat{n}{1}} \geq c_{\varepsilon}p_{n}} \geq 1-\varepsilon\]
for all \(\varepsilon\in(0,1)\) and for some \(c_{\varepsilon}>0\), and similarly for \(\fhat{n}{2}\) and \(q_[n]\).

The hold-out loss estimator is defined by
\begin{equation}\label{def:holoss}
    \ho(\fhat{n}{j}) = \sum_{i=n_{1}+1}^{n}\paren{y_{i} - \fhat{n_{1}}{j}(\x_{i})}^{2}\quad\text{for }j=1,2.
\end{equation}
The selection procedure consists in selecting the learning method \(\delta_{j}\) whose estimator \(\fhat{n}{j}\) minimizes \(\ho\) for \(j\in\set{1,2}\). We write \(\fho\) to denote the estimator selected by \(\ho\).

To show the consistency of \(\ho\), we will establish a few assumptions. First, we will assume the existance of two positive sequences \(\set{A_{n}}_{n\geq1}\) and \(\set{M_{n}}_{n\geq1}\) such that 
\begin{equation}\label{eq:lpconditions}
\norm{f-\fhat{n}{j}}_{\infty} = \Op{A_{n}}\quad\text{and}\quad\frac{\norm{f-\fhat{n}{j}}_{4}}{\norm{f-\fhat{n}{j}}_{2}} = \op{M_{n}}
\end{equation}
for \(j=1,2\). These rates of convergence will be used in the proof of Theorem~\ref{thm:yangth1} below. Note that the supnorm contition in (\ref{eq:lpconditions}) is satisfied if the regression function \(f\) and the estimators \(\fhat{n}{j}\) are bounded.

In addition to the above, we will assume that one of \(\delta_{1}\) and \(\delta_{2}\) is asymptotically better than the other. Indeed, if the latter is not satisfied, choosing one over the other may be irrelevant.

\begin{theorem}[\cite{yang_2007}]\label{thm:yangth1}
    Suppose that the conditions established above hold. Suppose, furthermore, that
    \begin{enumerate}
        \item \(n_{1}\to\infty\) as \(n\to\infty\)
        \item \(n_{2}\to\infty\) as \(n\to\infty\)
        \item \(n_{2}M_{n_{1}}^{-4} \to \infty\) as \(n\to\infty\)
        \item \(\sqrt{n_{2}}\max(p_{n_{1}}, q_{n_{1}})/\paren{1+A_{n_{1}}}\to\infty \) as \(n\to\infty\)
    \end{enumerate}
    Then, the hold-out CV procedure is consistent.
\end{theorem}

A very detailed proof of this result is given in~\textcite{yang_2007}, so it will be skipped here. We illustrate the conditions of Theorem~\ref{thm:yangth1} via an ideal-scenario example.

\begin{myproofbox}
    \textbf{Example: } Suppose that \(\fhat{n}{1}\) and \(\fhat{n}{2}\) are two nonparametric estimators with rates of convergence \(p_{n}=O\paren{n^{-4/9}}\) and \(q_{n}=O\paren{n^{-1/3}}\), respectively. Suppose that (\ref{eq:lpconditions}) is satisfied with \(A_{n} = O(1)\) and \(M_{n}=O(1)\). If we choose splits such that \(n_{1}\to\infty\) and \(n_{2}\to\infty\) as \(n\to\infty\), then \(n_{2}M_{n_{1}}^{-4}\) is clearly satisfied and 
    \[\frac{\sqrt{n_{2}}\max(p_{n_{1}}, q_{n_{1}})}{1+A_{n_{1}}} \geq \frac{n_{2}^{1/2}}{n_{1}^{1/3}}\to\infty \]
    is satisfied if \(n_{1}=o\paren{n_{2}^{3/2}}\). In other words, it is possible for the estimation size \(n_{1}\) to be dominating.

    On the other hand, if at least one of \(\fhat{n}{1}\) and \(\fhat{n}{2}\) has a parametric rate of convergence \(O(n^{-1/2})\), then
    \[\sqrt{n_{2}}\max(p_{n_{1}},q_{n_{1}})\geq \paren{\frac{n_{2}}{n_{1}}}^{1/2}\to\infty\]
    is satisfied whenever \(n_{2}/n_{1}\to\infty\). This agrees with the conclusion from Section~\ref{sec:lm}, in which we showed that cross-validation is often consistent if the validation size dominates.
\end{myproofbox}

\subsection{Voting cross-validation with multiple splits}

The majority-vote cross-validation method proceeds as follows:\footnote{The procedure desctibed here is theoretical in nature. In practice, we would not compute the hold-outs for all permutations of the data.} for each permutation \(i\mapsto\pi(i)\) of the data, we compute the estimators \(\fhat{n_{1}}{1}\) and \(\fhat{n_{1}}{2}\) using the first \(n_{1}\) data points,
\[E_{1} = \set{\paren{y_{\pi(1)}, \x_{\pi(1)}}, \ldots,\paren{y_{\pi(n_1)}, \x_{\pi(n_1)}}},\]
as the training sample and the remaining \(n_{2}=n-n_{1}\) elements as the validation sample. We then find the estimator that minimizes the hold-out loss
\[\hat{L}_{\pi}(\fhat{n}{j}) = \sum_{i=n_{1}+1}^{n}\paren{y_{\pi(i)} - \fhat{n_{1}}{j}\paren{\x_{\pi(i)}}}^{2}\qquad \text{for }j=1,2.\]
The chosen estimator is the one favored by the majority of the permutations. More formally, we define 
\[\tau_{\pi} = \ind{\hat{L}_{\pi}(\fhat{n}{1}) \leq \hat{L}_{\pi}(\fhat{n}{2})}\]
We then define our selection criterion as follows:
\[\hat{f}_{n} = \begin{cases}
    \fhat{n}{1} &\text{if }\sum_{\pi\in\Pi}\tau_{\pi} \geq {n!}/{2},\\[2mm]
    \fhat{n}{2} &\text{otherwise,}
\end{cases}\]
where \(\Pi\) denotes the set of all permutations of \([n]\).

\begin{theorem}[\cite{yang_2007}]\label{thm:yangth2}
    Under the conditions of Theorem~\ref{thm:yangth1} and the condition that the data is iid, the majority-vote cross-validation method is consistent.
\end{theorem}

\begin{myproofbox}
    \textit{Proof: }
    Suppose that \(\delta_{1}\) is asymptotically better than \(\delta_{2}\). For \(\pi\in \Pi\), we have that
    \[\prob\set{\hat{L}_{\pi}\paren{\fhat{n}{1}} \leq \hat{L}_{\pi}\paren{\fhat{n_{1}}{2}}} = \Ep{\tau_{\pi}} \stackrel{(*)}{=} \Ep{\frac{1}{n!}\sum_{\pi\in\Pi}\tau_{\pi}}.\]
    The equality at \((*)\) follows from the fact that the data are iid, hence exchangeable, and thus the \(\tau_\pi\) are identically distributed. By Theorem~\ref{thm:yangth1}, the right-hand side converges to 1 as \(n\to\infty\). Since the average \(1/n! \sum_{\pi}\tau_{\pi}\) is almost surely at most 1, it follows that \(1/n! \sum_{\pi}\tau_{\pi} \to 1\) in probability, and the majority-vote cross-validation method is consistent.\qed{}
\end{myproofbox}

The proof of Theorem~\ref{thm:yangth2} does not require using the entire set \(\Pi\) of permutations for the majority vote. In fact, Theorem~\ref{thm:yangth1} establishes that even a single data split suffices for consistency, provided the splitting conditions are met. Moreover, \textcite{yang_2007} presents a counterexample demonstrating that these conditions are not merely sufficient but necessary, hence showing that the number of splits does not affect consistency. In other words, multiple splits in cross-validation cannot rescue an inconsistent single-split procedure.

%A natural question, then, is: if multiple splits do not improve consistency, what is their benefit? This will be explored in a simulation later on.

\subsection{Concluding Remarks}

The theoretical results presented in this chapter highlight important distinctions between cross-validation for parametric and nonparametric procedures. Unlike Shao's results for parametric model selection, where the validation set must asymptotically dominate the training set to achieve consistency, our analysis shows that for nonparametric procedures, the training set can be dominant provided certain convergence conditions are satisfied. This contrast emphasizes that the optimal splitting strategy depends critically on the nature of the procedures being compared.

Cross-validation proves particularly useful for selection when comparing estimators with different convergence rates, as demonstrated in our theorems. The consistency of both single-split and majority-vote methods suggests that cross-validation can reliably identify asymptotically superior procedures under appropriate conditions on the \(L_{2}\), \(L_4\), and \(L_{\infty}\) norms of the estimation error. Not unlike the results in~\textcite{shao_1993}, however, the results in this section also indicate that leave-one-out cross-validation, where $n_1 = n-1$ and $n_2 = 1$, is generally inadequate for consistent selection since the validation size condition $n_2 \to \infty$ is violated.

While this section focused the voting approach, it is worth noting that the more common averaging approach (described, for example, in~\ref{sec:cv}) should, in theory, retain more information from the data. From a consistency perspective, \textcite{yang_2007} hypothesizes that both approaches are likely to be equivalent: if a majority of the permutations favour \(\fhat{n}{1}\), say, with high probability, then it is also likely that the average \((1/n!)\sum_{\pi\in\Pi}\hat{L}_{\pi}(\fhat{n}{1})\) will be smaller than that of \(\fhat{n}{2}\).

Several practical considerations emerge from this analysis, including the optimal choice of splitting ratios and the relative merits of k-fold procedures versus single splits. While our theoretical framework provides guidance on asymptotic properties, the finite-sample performance of these methods under various conditions remains an important question. These practical aspects, along with empirical comparisons between different cross-validation variants, will be addressed through simulation studies in a subsequent chapter.~\ref{sec:simulations}


\section{Aggregation}

It is no hard to see that the practice of model selection has some limitations and disadvantages. Without any means of verifying underlying hypotheses (say, linearity of \(f\) for linear models, or its membership to a Soblovev class for projection estimators), we have no guarantee that a single selected estimator will satisfy a desired performance. Moreover, model selection may arise challenges related to stability and overfitting, and may not even be helpful if the models being considered are hard to distinguish or if no clear winner exists among them. 

With this in mind, and if interpretability is not our main concern, we may instead opt to combine or \emph{aggregate} our candidate models to obtain a more robust and potentially better-performing estimator. Aggregation of multiple estimators consists in combining them via a weighted average. In fact, as will be shown below, model selection can be seen a special case of this broader framework, where the computed ``weighted average'' has weights equal to 0 for all but one candidate model. 

This section explores some perspectives through which aggregation schemes can be analyzed and presents asymptotic results on a particular aggregate estimator drawn from \textcite{bunea_2007}.

\subsection{Setup}

As before, we consider independent pairs in \(\data := \set{\paren{y_{i}, \x_{i}}:i\in [n]}\) satisfying the conditions established in Section~\ref{sec:setup}. Suppose that we have \(M\) candidate estimators of the regression function, denoted \(\fhat{n}{1}, \fhat{n}{2}, \ldots, \fhat{n}{M}\). Instead of selecting a single estimator, we combine them into an \emph{aggregate} \(\ftilde{\lambdahat{}}\) given by
\[\ftilde{\lambdahat{}} = \sum_{j=1}^{M}\lambdahat{j} \fhat{n}{j},\]
with \(\lambdahat{}:=\paren{\lambdahat{1}, \ldots, \lambdahat{M}}\in \Lambda\subset\R^{M}\) chosen to satisfy
\begin{equation}\label{eq:weights}
    \lambdahat{} = \argmin_{\lambda\in\Lambda}\set{\frac{1}{n}\normsq{y - f_{\lambda}(\x)} - \mathrm{pen}(\lambda)}
\end{equation}
for some penalty \(\mathrm{pen}(\lambda)\) on the coefficients.

\subsubsection{Four types of aggregation}

We will consider four aggregation schemes as presented in~\textcite{bunea_2007}, each of which is characterized by a different set \(\Lambda\) of admissible weights \(\lambdahat{}\):
\begin{itemize}
    \item Model Selection Aggregation (MS): A single estimator is selected. That is,\[\Lambda_{\mathrm{MS}} = \set{\lambda\in\R^{M}:\lambda = \boldsymbol{e}_{j}\text{ for some }j\in[M]}.\]
    \item Linear Aggregation (L): \(\ftilde{\lambdahat{}}\) is chosen among all linear combinations of the estimators. That is, \[\Lambda_{\mathrm{L}} = \R^{M}.\]
    \item Convex Aggregation (C): \(\ftilde{\lambdahat{}}\) is chosen among all convex combinations of the estimators. That is, \[\Lambda_{\mathrm{C}} = \set{\lambda\in\R^{M}:\lambda\geq 0, \sum_{j=1}^{M}\lambda_{j} = 1}.\]
    \item Subset Selection (S): We select and aggregate at most \(D\) estimators from the pool, for a given \(D\leq M\). That is, \[\Lambda_{\mathrm{S}} = \set{\lambda\in\R^{M}:\lambda\text{ has at most \(D\) non-zero entries}}.\]
\end{itemize}

\subsubsection{Evaluating the aggregate}

In an ideal scenario, we would like to select  weights \(\lambda^*\) satisying 
\[\lambda^{*} = \argmin_{\lambda\in\Lambda}\Ep{d\paren{f, \ftilde{\lambda}}}\]
for some distance function \(d\) (e.g., the \(L_{2}\) norm). However, since the true regression function \(f\) is unknown, this approach is clearly not feasible. Another way of constructing an estimator is to minimize its maximum risk on a class of functions \(\Theta\) containing \(f\). That is, we would like to find \(\lambdahat{}\) satisfying 
\[\sup_{f\in\Theta}\E\normsq{f-\ftilde{\lambdahat{}}}_{2} = \inf_{\lambda\in\Lambda}\sup_{f\in\Theta}\E\normsq{f-\ftilde{\lambda}}_{2}.\]
This is known as \emph{minimax} extimation. 
However, once again, there is no obvious way to compute the expectation \(\E\normsq{f-\ftilde{\lambdahat{}}}_{2}\) for an arbitrary \(f\in\Theta\).

For these reasons, we instead adopt the least-squares approach in (\ref{eq:weights}). But how can we know if this approach is any good? We need a tool to evaluate the performance of our aggregate against \emph{any} possible of regression function \(f\). Oracles provide us with such a tool. 

\begin{definition}[adapted from~\cite{tsybakov_introduction_2009}]
    Suppose that there exists \(\lambda^{*}\in\Lambda\) such that 
    \[\E\normsq{f-\ftilde{\lambda^{*}}}_{2} = \inf_{\lambda\in\Lambda}\E\normsq{f-\ftilde{\lambda^{*}}}_{2}.\]
    The function \(f\mapsto \ftilde{\lambda^{*}}\) is called the oracle of aggregation under \(L_{2}\).

    We say that the aggregate \(\ftilde{\lambdahat{}}\) {mimics} the oracle if
    \begin{equation}\label{eq:oracleineq}
        \E\norm{f - \ftilde{\lambdahat{}}}_{2} \leq \inf_{\lambda\in\Lambda}\E\norm{f - \ftilde{\lambda}}_{2} + \Delta_{n,M}.
    \end{equation}
    for the smalles possible \(\Delta_{n,M}>0\) independent of \(f\).
\end{definition}

In what follows, the goal is to find lower bounds on \(\Delta_{n,M}\) for each of the aggregation schemes. 

\begin{definition}[\cite{tsybakov_introduction_2009}]
    For a class of functions \(\Theta\), a sequence \(\set{\psi_{n}}_{n\geq1}\) of positive numbers is called an \emph{optimal rate of convergence} of estimators \(\hat{f}\) on \(\Theta\) under \(L_{2}\) if there exist constants \(c, C>0\) such that
    \begin{align}
        &\limsup_{n\to\infty}\paren{\psi_{n}^{-2}\inf_{\hat{f}}\sup_{f\in\Theta}\Ep{\norm{f - \hat{f}}_{2}^{2}}}\leq C\\
        \text{and}\qquad&\liminf_{n\to\infty}\paren{\psi_{n}^{-2}\inf_{\hat{f}}\sup_{f\in\Theta}\Ep{\norm{f - \hat{f}}_{2}^{2}}}\geq c
    \end{align}
    \textcolor{red}{An estimator \(\hat{f}_{n}\) is said to be \emph{rate-optimal} if 
    \[\sup_{f\in\Theta}\Ep{\norm{f - \hat{f}_{n}}_{2}^{2}} \leq C'\psi_{n}^{2}\]
    for some \(C'>0\). It is called \emph{asymptotically efficient} of \(\Theta\) under \(L_{2}\) if 
    \[\lim_{n\to\infty}\frac{\sup_{f\in\Theta}\E{\normsq{f-\hat{f}_{n}}}}{\inf_{\hat{f}}\sup_{f\in\Theta}\E{\norm{f - \hat{f}}_{2}^{2}}}=1.\]}
\end{definition}

We adapt Theorem 5.1 in~\textcite{bunea_2007} to consider exclusively the \(L_{2}\) norm:

\begin{theorem}[\cite{bunea_2007}]\label{prop:buneath5.1}
    \textcolor{red}{(Statement of lower bounds)}
    \[\sup_{f_1, \ldots, f_2\in\mathcal{F}_{0}} \inf_{T_n}\sup_{f\in\mathcal{F}_0} \set{\E\normsq{f - T_n}_{2} - \min_{\lambda\in\Lambda}\normsq{f - \ftilde{\lambda}}_{2}} \geq c\psi_{n}\]
    \textcolor{red}{INCOMPLETE SECTION}
\end{theorem}

\subsection{A BIC-type penalty}
\begin{definition}
    For \(\lambda\in\Lambda\), let \(M(\lambda) := \norm{\lambda}_{0}\) (i.e., the number of non-zero coefficients in \(\lambda\)) and write
    \[L(\lambda) = 2\log\paren{\frac{eM}{\min(M(\lambda), 1)}}.\]
    For \(a>0\), we define the Bunea-Tsybakov-Wegkamp \textcolor{red}{(I don't know what to call it)} penalty to be
    \[\penBIC{\lambda} := \frac{2\sigma^{2}}{n}M(\lambda)\paren{1+\frac{2+a}{1+a}\sqrt{L(\lambda)} + \frac{1+a}{a}{L(\lambda)}}.\]
    This penalty yields the BIC-type least-squares aggregate \(\ftilde{\mathrm{BIC}} := \ftilde{\lambdahat{\mathrm{BIC}}}\) with 
    \[\lambdahat{BIC}=\argmin_{\lambda\in\R^{M}}\set{\frac{1}{n}\normsq{\y - f_{\lambda}(\x)} - \penBIC{\lambda}}\]
\end{definition}

The theorem below relies on the two following lemmas, which are stated without proof:

\begin{lemma}\label{lemm:binombound}
    For positive integers \(m \leq M\),
    \[\binom{M}{m} \leq \paren{\frac{eM}{m}}^m.\]
\end{lemma}

\begin{lemma}[Adapted from Birgé et al., 2001 \textcolor{red}{(REF)}]\label{lemm:birge}
    Suppose that there exists a family of sets \(\set{\Lambda_{\alpha}}_{\alpha\in\Acal}\) and integers \(\set{m_{\alpha}}\) such that \(M(\lambda) = m_{\alpha}\) for all \(\lambda\in\Lambda_{\alpha}\). Suppose, furthermore, that there exists a family of non-negative weights \(\set{L_{\alpha}}_{\alpha\in\Acal}\) satisfying 
    \[\Sigma:=\sum_{\alpha\in\Acal}\exp\paren{-m_{\alpha}L_{\alpha}}<\infty.\]
    Let \(\theta\in(0,1)\) and \(K>2-\theta\). If there exists a finite subset \(\bar{\Acal}\subset\Acal\) such that, for all \(\alpha\in\Acal\setminus\bar{\Acal}\), 
    \[\mathrm{pen}(\lambda)\geq \frac{\sigma^2}{n}M(\lambda)\paren{K + 2(2-\theta)\sqrt{L_{m}} +2{\theta^{-1}}L_{m}} =: Q_{\lambda}\qquad\text{whenever }\lambda\in\Lambda_{\alpha}.\]
    Then, the corresponting aggregate \(\ftilde{\lambdahat{}}\) defined by (\ref{eq:weights}) exists almost surely and satisfies
    \begin{equation}
        \paren{1-\theta}\Ep{\normsq{f - \ftilde{\lambdahat{}}}} \leq \inf_{\lambda\in\Lambda}\set{\normsq{f - \ftilde{\lambda}} + \mathrm{pen}(\lambda) - \frac{\sigma^2}{n}M(\lambda)} + \sup_{\lambda\in\Lambda}\set{Q_{\lambda} - \mathrm{pen}} + 
    \end{equation}

\end{lemma}
\textcolor{red}{NOTE: Here, \(\Acal\) will be \(\set{(m,k):m\leq M, k\leq \binom{M}{m}}\). It's different than in previous sections, but it's similar in that it denotes a subset of the \(\fhat{n}{j}\).}

\begin{theorem}[\cite{bunea_2007}]\label{prop:buneath31}
    Assume that the \(e_{i}\) are iid \(\Ncal(0, \sigma^{2})\) and that the functions \(f, \fhat{n}{1}, \ldots, \fhat{n}{M}\) are uniformly bounded. Then, for all \(a>0\), \(M\geq 2\), and \(n\geq 1\),
    \begin{align*}
        \E\normsq{\ftilde{\mathrm{BIC}} - f} &\leq (1+a)\inf_{\lambda\in\R^{M}}\set{\normsq{\ftilde{\lambda} - f} + \frac{\sigma^{2}}{n}\paren{5+\frac{2+3a}{a}{L(\lambda)}}M(\lambda)} + \frac{6\sigma^{2}{(1+a)}^{2}}{an(e-1)}
    \end{align*}

\end{theorem}

Theorem~\ref{prop:buneath31} implies that \(\ftilde{\mathrm{BIC}}\) mimics the oracles for all four aggregation types.

\newpage
\printbibliography{}
\end{document}