\documentclass[11pt, letter paper]{article}
\usepackage{amsmath,amsthm,amsfonts,amssymb,fancyhdr,graphicx,xcolor}
\usepackage{geometry}
\usepackage{enumerate}
\usepackage[style=authoryear, maxcitenames=1, dashed=false]{biblatex}
%\usepackage{minted}
\usepackage[most]{tcolorbox}

\addbibresource{citations.bib}
\geometry{letterpaper, margin=1in}

% For indicator functions:
\DeclareMathAlphabet{\mathmybb}{U}{bbold}{m}{n}
\newcommand{\1}{\mathmybb{1}}

%\newtcolorbox[auto counter, number within=section]{proposition}[2][Proposition]{%
%  colframe=blue!50!black,
%  colback=blue!10,
%  coltitle=white,
%  fonttitle=\bfseries,
%  title=#1~\thetcbcounter\ifx#2\empty\else~(#2)\fi}
%
%\newtcolorbox[auto counter, number within=section]{definition}{%
%  fonttitle=\bfseries,
%  title=Definition~\thetcbcounter,
%  label={def:\thetcbcounter}}

\newtcolorbox{myproofbox}{
  breakable,
  colback=white,
  colframe=black,
  boxrule=0.5pt,
  arc=0mm,
  left=1mm,
  right=1mm,
  top=1mm,
  bottom=1mm
}

\newtheorem{definition}{Definition}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{theorem}[proposition]{Theorem}
\newtheorem{corollary}[proposition]{Corollary}
\newtheorem{lemma}[proposition]{Lemma}

\DeclareMathOperator*{\argmin}{arg\,min}

\newcommand{\R}{\mathbb{R}}
\newcommand{\Borel}[1]{\mathcal{B}\paren{#1}}
\newcommand{\0}{\emptyset}
\newcommand{\prob}{\mathbb{P}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Ep}[1]{\mathbb{E}\left[ #1 \right]}
\newcommand{\paren}[1]{\left(#1 \right)}
\newcommand{\sqbr}[1]{\left[#1 \right]}
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\norm}[1]{|\hspace{-1pt}|#1 |\hspace{-1pt}|}
\newcommand{\normsq}[1]{\norm{#1}^{2}}
\newcommand{\ind}[1]{\mathmybb{1}_{\sqbr{#1}}}
\newcommand{\data}{\mathcal{D}_{n}}
\newcommand{\Hcal}{\mathcal{H}}
\newcommand{\Acal}{\mathcal{A}_{n}}
\newcommand{\Tcal}{\mathcal{T}_{n}}
\newcommand{\Ncal}{\mathcal{N}}
\newcommand{\Mcal}{\mathcal{M}}
\newcommand{\Fcal}{\mathcal{F}}
\newcommand{\aseq}{\stackrel{\mathrm{a.s.}}{=}}
\newcommand{\X}{\boldsymbol{X}}
\newcommand{\x}{\boldsymbol{x}}
\newcommand{\z}{\boldsymbol{z}}
\newcommand{\y}{\boldsymbol{y}}
\newcommand{\e}{\boldsymbol{e}}
\newcommand{\Cov}[1]{\mathrm{Cov}\paren{#1}}
\newcommand{\bbeta}{\boldsymbol{\beta}}
\newcommand{\bbetahat}{\boldsymbol{\hat{\beta}}}
\newcommand{\bepsilon}{\boldsymbol{\epsilon}}
\newcommand{\Loss}[1]{L_{n}\paren{#1}}
\newcommand{\Rhat}[2]{\hat{R}_{n, #1}\paren{#2}}
\newcommand{\alphahat}[1]{\hat{\alpha}^{#1}}
\newcommand{\alphatilde}{\tilde{\alpha}}
\newcommand{\alphabar}{\bar{\alpha}}
\newcommand{\lev}{h_{ii,\alpha}}
\newcommand{\loocv}[1]{\hat{R}^{(1)}_{n}\paren{#1}}
\newcommand{\ho}{\hat{L}_{\mathrm{ho}}}
\newcommand{\op}[1]{o_{\prob}\paren{#1}}
\newcommand{\Op}[1]{O_{\prob}\paren{#1}}
\newcommand{\sigmahat}{\hat{\sigma}^{2}_{n}}
\newcommand{\fhat}[2]{\hat{f}_{#1, #2}}
\newcommand{\ftilde}[1]{\tilde{f}_{#1}}
\newcommand{\lambdahat}[1]{\hat{\lambda}_{#1}}
\newcommand{\blambdahat}{\boldsymbol{\hat{\lambda}}}
\newcommand{\pen}[1]{\mathrm{pen}\paren{#1}}
\newcommand{\penBIC}[1]{\mathrm{pen}_{\mathrm{BIC}}\paren{#1}}
\newcommand{\tr}[1]{\mathrm{tr}\paren{#1}}
\newcommand{\ols}[1]{\paren{\X^{\top}_{#1}\X_{#1}}\X^{\top}_{#1}\y}
\newcommand{\fho}{\hat{f}^{(\mathrm{ho})}_{n}}

\title{MATH 410 Report: The Asymptotics of Cross-Validation and Aggregation in the Regression Setting}
\author{Diego Urdapilleta de la Parra}
\begin{document}

\maketitle
\tableofcontents

\newpage
\section{Introduction: The problem of model selection}

Model selection lies at the heart of statistical learning and predictive modeling. Given a set of candidate models, each representing different assumptions and levels of complexity, the central challenge is to identify the one that balances interpretability, computational feasibility, and predictive accuracy. This task is rendered especially delicate by the fundamental tension between model simplicity and flexibility.

From a computational standpoint, simpler models are often preferable: they require less processing time, are easier to implement, and tend to be more stable numerically. In statistical terms, parsimony can translate into greater efficiency, as models with fewer parameters typically have a lower variance in their estimates. However, an overly simplistic model may fail to capture essential patterns in the data, resulting in high bias and poor predictive performance. Conversely, highly flexible models, while potentially better at capturing complex relationships, may obfuscate the true signal and are more prone to overfitting noise.

Each model or regression procedure typically rests on a set of theoretical assumptions that are rarely, if ever, fully verifiable in practice. This uncertainty makes it prudent to consider and compare multiple competing models rather than rely solely on a priori reasoning.

Cross-validation methods provide a data-driven framework for navigating these trade-offs. By estimating a model's predictive performance on unseen data, cross-validation enables an empirical basis for comparison, reducing the reliance on unverifiable assumptions and helping to guard against both under- and overfitting. As such, it plays a crucial role in modern approaches to model selection, where the goal is not just to fit the data well, but to generalize effectively to new observations.

Thus, as is generally the case in statistics, the need for model selection stems from an uncertainty or lack of knowledge about whatever system is being studied, and while selection procedures may give us improved confidence on our estimation endeavours, it certainly is not a perfect cure for our ignorance. Rather than committing to a single estimator, another way of coping with our lack of knowledge is to combine or \emph{aggregate} our candidate models. This way, we may obtain a more robust and potentially better-performing estimator.

In this paper, we study two frameworks for model selection in the regression setting, with a focus on the asymptotic properties of cross-validation methods. We then investigate aggregation as an alternative approach, examining the asymptotic guarantees that it can provide us with. Finally, we perform a simulation study where we compare the performance of multiple of the procedures treated. The goal of this project is to offer insight into how different model selection and aggregation strategies perform in finite-sample scenarios. By contrasting their empirical behavior with their asymptotic properties, we aim to provide a nuanced understanding of when and why certain methods may be preferable, thereby guiding more informed decisions in real-world predictive modeling tasks.

\subsection{Setup and notation}\label{sec:setup}

Throughout this report, we consider the following regression setup. For positive integers \(n\) and \(p_{n}\), let \((y, \x):\Omega\to\R\times{[0,1]}^{p_{n}}\) be a real-valued random vector with distribution \(\mu_{y, \x}\) such that \(\E{|y|^{2}}<\infty\), \(\E\normsq{\x}<\infty\), and \(\Ep{\x\x^{\top}}\succ 0\). A Borel-measurable function \(f:{[0,1]}^{p_{n}} \to \R\) that satisfies
\begin{equation}\label{eq:setup}
    f(\x) \aseq \Ep{y\mid \x}
\end{equation}
is called the \emph{regression} function of \(y\) on \(\x\).\footnote{Technically, it would be more accurate to refer to \emph{a version of} the regression function \(f\), since it is only unique in the almost-sure sense. In this report, however, we adopt the common convension of treating \(f\) as a single, well-defined function.}

We are treat \(y\) as a response and \(\x\) as a covariate vector, and we would like to estimate the regression function \(f\) from sampled data. To this end, suppose that we have a sample \(\data := \set{\paren{y_{i}, \x_{i}}:i\in [n]}\) of independent data points drawn from the distribution \(\mu_{y, \x}\). We define the residual \(\epsilon_{i}:= y_{i} - f(\x_{i})\), which yields the decomposition
\[y_{i} = f(\x_{i}) + \epsilon_{i}, \quad i\in[n],\]
(here and throughout this paper, the notation \([n]\) denotes the set \(\set{1, \ldots, n}\)).
In general, we will assume that the second moment \(\Ep{\epsilon^{2}_{i}\mid\x}\) is bounded almost surely. We may also abuse notation by writing
\[\y_{n} = f(\X_{n}) + \bepsilon_{n},\]
where  \(\y_{n}\) is the vector of responses, \(\bepsilon_{n}\) is the vector of residuals, \(\X_{n} = {[\x_{1}^{\top}\;\cdots\;\x_{n}^{\top}]}^{\top}\) denotes the design matrix, and \(f(\X_{n}) = (f(\x_{1}),\ldots,f(\x_{n}))\).

We will use the notation \(\norm{\cdot}\) to denote the Euclidean norm on \(\R^{n}\) (and, in some contexts, other finite-dimensional vector spaces on \(\R\)). At the same time, for \(q\geq 1\) and \(g\in L_{q}([0,1], \mathcal{B}[0,1], \mu_{\x})\), we write 
\[\norm{g}_{q} := \begin{cases}
    \paren{\int|g|^{q}\,d\mu_{\x}}^{1/q}&\text{if }1\leq q < \infty,\\[2mm]
    \sup\set{c\in\R:\mu_{\x}\set{|f|>c}>0} &\text{if } q = \infty,
\end{cases}\]
where \(\mathcal{B}[0,1]\) denotes the Borel \(\sigma\)-field over \([0,1]\) and \(\mu_{\x}\) denotes the marginal distribution of \(\x\).


\subsection{Cross-validation}\label{sec:cv}

Cross-validation refers to a family of methods for loss/risk estimation. In its most general form, cross-validation proceeds as follows. 

Suppose that we wish to estimate the loss \(L_{n}\) of a model \(\hat{f}\) against \(f\). Let \(J\) be an index set and let \(\set{E_{j}}_{j\in J}\) be a family of subsets \(E_{j}\subset [n]\) such that \(|E_{j}|=n_{1}\) for all \(j\in J\), and write \(V_{j} := E_{j}^{c}\). The integer \(n_{1}\), chosen beforehand, is called the \emph{estimation size}, and it denotes the number of data points used for fitting the model \(\hat{f}\) on the training phase. For each subset \(E_{j}\), we consider the estimation sample \(\data^{E_{j}}\) of \(n_{1}\) data ponts given by
\[\data^{E_{j}} = \set{\paren{y_{i}, \x_{i}}\in\data :i\in E_{j}}.\]
For each \(j\in J\), we fit the model \(\hat{f}\) on the estimation sample \(\data^{E_{j}}\) and compute the \emph{hold-out} loss against the remaining \(n-n_{1}=: n_{2}\) data points in \(\data^{V_{j}}\):
\[\hat{R}_{n}^{E_{j}} = \frac{1}{n_{2}}\sum_{i \in V_{j}} \paren{y_{i} - \hat{f}\paren{\x_{i};\data^{E_{j}}}}^{2}\]
Finally, we combine the hold-out estimates into an overall cross-validation loss estimate
\[\hat{R}^{CV}_{n}:= \frac{1}{|J|}\sum_{j\in J}\hat{R}_{n}^{E_{j}}.\]

Many popular variants of this procedure exist, and these are often characterized by the choices of \(J\) (e.g., all possible subsets versus a fixed number) and estimation size \(n_{1}\) (e.g., \(n_{1}=n-1\) for the \emph{leave-one-out} method, \(n_{1}=n-d\) for the \emph{delete-\(d\)} method, or \(n_{1} = n(k-1)/k\) for the \emph{\(k\)-fold} method). Sometimes, as we will see in Section~\ref{sec:yang}, alternative approaches for combining the hold-outs are carried out.

We will begin our exploration of the properties of some of these methods with a treatment of linear models. Then, we will move on to a more general framework where no such restrictions are imposed on \(f\), and we will treat problems of selection on a much broader class of estimators.

\section{Variable Selection for Linear Models}\label{sec:lm}
\subsection{Setup}\label{sec:lmsetup}
In this section, the regression function \(f\) in (\ref{eq:setup}) is assumed to be linear, so that the data is generated from a linear model of the form
\[\y = \X\bbeta + \e\]
where \(\X = {[\x_{1}^{\top}\;\x_{2}^{\top}\;\cdots\;\x_{n}^{\top}]}^{\top}\in\R^{n\times p_{n}}\) is the design matrix, \(\y = \sqbr{y_{1}\; y_{2}\;\cdots\; y_{n}}^{\top}\), and \(\e\) is a mean-zero random vector with \(\Cov{\e} = \sigma^{2}\boldsymbol{I}_{n}\).

In the context of linear models, the model selection procedure reduces to selecting a subset of covariates from a set of candidate covariates of size \(p_n\). This is also known as \emph{variable selection}. We remark that the number \(p_n\) may depend on \(n\), and some assumptions on the growth of \(p_n\) will be established later.

We let \(\Acal\subset2^{[p_{n}]}\) be a family of index sets representing candidate models. For \(\alpha\in\Acal\), we denote by \(p_{n}(\alpha)\) the cardinality of \(\alpha\) and consider the model given by
\[f_{\alpha}(\X) = \X_{\alpha}\bbeta_{\alpha},\]
where \(\X_{\alpha}\) is the sub-matrix of \(\X\) containing only the columns indexed by \(\alpha\), and \(\bbeta_{\alpha}\) is the coefficient vector containing only the entries indexed by \(\alpha\) in \(\bbeta\). To perform the regression task on these models, we utilize the \emph{Ordinary Least Squares} (OLS) estimator \(\bbetahat_{\alpha}\) of \(\bbeta_{\alpha}\), which is given by
\[\bbetahat_{\alpha} = \ols{\alpha}.\]

We will use the variable selection framework outlined by the following definitions:

\begin{enumerate}
    \item We say \(\alpha\in\Acal\) is \emph{correct} if \(\Ep{\y\mid\X}\aseq f_{\alpha}(\X)\), and we denote by \(\Tcal\) the set of correct models in \(\Acal\).
    \item We say \(\alpha\in\Acal\) is \emph{wrong} if it is not correct, and we denote by \(\Tcal^{c}\) the set of wrong models in \(\Acal\).
    \item We say \(\Acal\) is \emph{embedded} if there exists an enumeration \(\alpha_{1}, \alpha_{2}, \ldots, \alpha_{k}\) of all elements in \(\Acal\) such that \[\alpha_{1}\subset\alpha_{2}\subset\cdots\subset\alpha_{k}.\]
\end{enumerate}

Throughout this section, we will also use the notations \(H_{\alpha} = \X_{\alpha}\paren{\X_{\alpha}^{\top}\X_{\alpha}}\X_{\alpha}^{\top}\) for the hat matrix, \(M_{\alpha}:=I_{n}-H_{\alpha}\) for the anihilator matrix, and \(h_{ii,\alpha}:=\x_{i\alpha}^{\top}{(\X_{\alpha}^{\top}\X_{\alpha})}^{-1}\x_{i\alpha}\) for the \(i\)th leverage corresponding to \(\alpha\in\Acal\).

In order to select one model over another, we need some way to measure and compare the quality of their predictive ability. A natural approach is to consider the distance between their estimated mean outcomes and the true mean structure given by \(f\). We define th

\begin{definition}\label{def:loss}
    For \(\alpha\in\Acal\), let \(\bbetahat_{\alpha}\) be the OLS estimator of \(\bbeta_{\alpha}\) and \(\hat{f}_{\alpha}(\X):=\X_{\alpha}\bbetahat_{\alpha}\). We denote the average squared error of \(\hat{f}_{\alpha}\) by
    \[\Loss{\alpha}:=\frac{1}{n}\normsq{f(\X) - \hat{f}_{\alpha}\paren{\X}}.\]
    Additionally, we write
    \[R_{n}(\alpha):= \Ep{\Loss{\alpha}\mid\X}.\]
\end{definition}

The following conditions will be useful throughout our treatment of linear models:
\begin{align*}
    &\mathbf{H1:}\qquad \liminf_{n\to\infty} \frac{1}{n}\normsq{M_{\alpha}\X\bbeta}>0 \text{ almost surely for all }\alpha \in\Tcal^{c}.\\
    &\mathbf{H2:} \qquad \Ep{\normsq{\x}}<\infty.\\[2.5mm]
    &\mathbf{H3:}\qquad \lim_{n\to\infty}\max_{i\leq n}\,h_{ii,\alpha} \aseq 0 \text{ for all }\alpha \in\Acal.\\
    &\mathbf{H4:}\qquad \sum_{\alpha\in\Tcal^{c}}\frac{1}{\paren{nR_{n}(\alpha)}^{m}}\to_{\prob}0\text{ and }\Ep{e_i^{4m}\mid\x_i}<\infty\quad\text{for some }m\geq 1.
\end{align*}

Condition \textbf{H1} establishes a minimal difference in predictive ability between correct and wrong models. It ensures that the signal be strong enough that the distinction between correct and wrong matters. Indeed, if there is no meaningful difference in performance between the two sets, we need not to worry about selection.
\textbf{H2} and \textbf{H4} are moment conditions that will allow us to derive convergence and apply the law of large numbers to derive asymptotic results.
Finally, condition \textbf{H3} ensures that there are no overly-influential data points in the models. It will be utilized, for instance, to prove some asymptotic properties of the Leave-one-out loss estimator.

We now state two preliminary results the justify are choice of \(L_{n}\) and \(R_{n}\) for selection purposes. 

\begin{proposition}\label{prop:lossshao}
    Assuming the setup of Definition~\ref{def:loss}, the following equalities hold almost surely:
    \[\Loss{\alpha} = \frac{1}{n}\normsq{H_{\alpha}\e} + \frac{1}{n}\normsq{M_{\alpha}\X\bbeta}\quad\text{and}\quad R_{n}(\alpha) = \frac{1}{n}\sigma^{2}p_{n}(\alpha) + \frac{1}{n}\normsq{M_{\alpha}\X\bbeta}\]
    where \(H_{\alpha} = \X_{\alpha}\paren{\X_{\alpha}^{\top}\X_{\alpha}}^{-1}\X_{\alpha}^{\top}\) and \(M_{\alpha}= I_{n} - H_{\alpha}\).
\end{proposition}

\begin{myproofbox}
    \textit{Proof: }
    First, we have that
    \begin{align*}
        \normsq{f(\X) - \hat{f}_{\alpha}(\X)} &= \normsq{\X\bbeta - \X_{\alpha}\bbetahat_{\alpha}}\\
        &= \normsq{\X\bbeta - H_{\alpha}\paren{\X\bbeta + \e}}\\
        &= \normsq{M_{\alpha}\X\bbeta - H_{\alpha}\e}.
    \end{align*}
    Notice that \(M_{\alpha}\X\bbeta\) and \(H_{\alpha}\e\) are orthogonal:
    \[\e^{\top}H_{\alpha}M_{\alpha}\X\bbeta  = \e^{\top}H_{\alpha}\paren{I_{n} - H_{\alpha}}\X\bbeta = \e^{\top}H_{\alpha}\X\bbeta - \e^{\top}H_{\alpha}\X\bbeta = 0.\]
    Hence, the first part follows from the Pythagorean theorem.

    For the second part, we note that \[\Ep{\normsq{H_{\alpha}\e}\mid\X} \aseq \tr{\Ep{\normsq{H_{\alpha}\e}\mid\X}} \aseq \Ep{\tr{\normsq{H_{\alpha}\e}}\mid\X},\]
    so that
    \begin{align*}
        \Ep{\normsq{H_{\alpha}\e}\mid\X} &= \Ep{\tr{\e^{\top}H_{\alpha}\e}\mid\X}\\
        &= \Ep{\tr{\e\e^{\top}H_{\alpha}}\mid\X}\\
        &= \tr{\Ep{\e\e^{\top}\mid\X}H_{\alpha}}\\
        &= \sigma^2\tr{H_{\alpha}}\\
        &= \sigma^{2}p_{n}(\alpha),
    \end{align*}
    where \(p_{n}(\alpha)\) denotes the size of model \(\alpha\).\qed{}
\end{myproofbox}

\begin{proposition}\label{prop:Ropt}
    Suppose that that \(\Tcal\) is non-empty, and let \(\alpha^{*}_{n}\) be the smallest correct model in \(\Tcal\). Then, \(\alpha^{*}_{n}\) minimizes \(R_{n}(\alpha)\) over \(\alpha\in\Acal\) with probability 1.
\end{proposition}

\begin{myproofbox}
    \textit{Proof: }
    Let \(\alpha\in\Acal\) be arbitrary and suppose that \(\alpha\in\Tcal\). Then, \(\X_{\alpha}\bbeta_{\alpha} = \X\bbeta\) and \(p_{n}(\alpha_{n}^{*})\leq p_{n}(\alpha)\). Thus,
    \begin{align*}
        R_{n}(\alpha) &= \frac{1}{n}\sigma^{2}p_{n}(\alpha) + \frac{1}{n}\normsq{M_{\alpha}\X\bbeta}\\[2mm]
        &= \frac{1}{n} \sigma^{2}p_{n}(\alpha) + \frac{1}{n}\underbrace{\normsq{M_{\alpha}\X_{\alpha}\bbeta_{\alpha}}}_{0}\\
        &= \frac{1}{n}\sigma^{2}p_{n}(\alpha)\; \geq \; \frac{1}{n}\sigma^{2}p_{n}(\alpha_{n}^{*}) = R_{n}(\alpha_{n}^{*}).
    \end{align*}
    Now suppose that \(\alpha\in\Tcal^{c}\). If \(p_{n}(\alpha)\geq p_{n}(\alpha_{n}^{*})\), the result follows immediately by assumption H1. On the other hand, if \(p_{n}(\alpha)\leq p_{n}(\alpha_{n}^{*})\), we must verify that
    \begin{equation}\label{eq:Roptgoal}
        \normsq{M_{\alpha}\X\bbeta} \geq \sigma^{2}\paren{p_{n}(\alpha_{n}^{*}) - p_{n}(\alpha)}.
    \end{equation}
    To this end, we note that \(\normsq{M_{\alpha}\X\bbeta} = \normsq{M_{\alpha}\X_{\alpha_{n}^{*}}\bbeta_{\alpha_{n}^{*}}}\) and that 
    \[\X_{\alpha_{n}^{*}}\bbeta_{\alpha_{n}^{*}} = \X_{\alpha}\bbeta_{\alpha} + \X_{\alpha_{n}^{*}\setminus\alpha}\bbeta_{\alpha_{n}^{*}\setminus\alpha} .\]
    Thus, if we let \(\lambda\) denote the smallest eigenvalue of \(\X_{\alpha_{n}^{*}}^{\top}M_{\alpha}\X_{\alpha_{n}^{*}}\), we have that
    \[\normsq{M_{\alpha}\X\bbeta} = \normsq{M_{\alpha}\X_{\alpha_{n}^{*}\setminus\alpha}\bbeta_{\alpha_{n}^{*}\setminus\alpha}} \geq \lambda\normsq{\bbeta_{\alpha*\setminus\alpha}}\]
    (for a proof of the latter inequality, see~\textcite{hansen_2022}).
    \textcolor{red}{This is as far as I got. I don't know how to show that \(\lambda\normsq{\bbeta_{\alpha_{n}^{*}\setminus\alpha}}\geq \sigma^{2}\paren{p_{n}(\alpha_{n}^{*}) - p_{n}(\alpha)}\), but it seems reasonable if the coefficients in \(\bbeta\) are not too small.}\qed{}
\end{myproofbox}

From Proposition~\ref{prop:Ropt}, we see that \(R_{n}\) is an effective selection criterion. Unfortunately, \(R_{n}\) is an unkown expectation that depends on the regression function \(f\), and therefore cannot be used in practice. Instead, we may try to approximate it through some other empirically feasible criterion, \(\hat{R}_{n}\), which we treat as an ``estimator'' of the random quantity \(R_{n}\).

\begin{definition}\label{def:consistency97}
    Let \(\hat{R}_{n}\) be a model selection criterion and let \(\alphahat{}_{n}\) be the model selected by minimizing \(\hat{R}_{n}\) over \(\Acal\). Let \(\alpha^{*}_{n}\) denote the model minimizing \(R_{n}\) over \(\Acal\). We say that \(\hat{R}_{n}\) is {consistent} if 
    \[\prob\set{\alphahat{}_{n} = \alpha^{*}_{n}}\to 1\]
    as \(n\to\infty\). We say that \(\hat{R}_{n}\) is {assymptotically loss efficient} if 
    \[\frac{L_{n}(\alphahat{}_{n})}{L_{n}(\alpha^{*}_{n})}\xrightarrow{\prob} 1.\]
\end{definition}

Consistency as defined above is a naturally desirable property for any selection criterion \(\hat{R}_{n}\): it ensures that, asymptotically, \(\hat{R}_{n}\) will select the same model as the optimal risk \(R_{n}\). Asymptotic loss efficiency is a weaker property that captures a certain degree of ``closeness'' between \(\alphahat{}_{n}\) and \(\alpha^{*}_{n}\). All consistent criteria are asymptotically loss efficient:

\begin{lemma}\label{lemm:implication}
    If \(\hat{R}_{n}\) is consistent, then it is asymptotically loss efficient.
\end{lemma}

\begin{myproofbox}
    \textit{Proof: }
    Suppose that \(\hat{R}_{n}\) is consistent. Clearly, if \(\alphahat{}_{n} = \alpha^{*}_{n}\), then \(\Loss{\alphahat{}} = \Loss{\alpha^{*}_{n}}\). Therefore, 
    \[\prob\set{\alphahat{}_{n} = \alpha^{*}_{n}}\leq \prob\set{\Loss{\alphahat{}} = \Loss{\alpha^{*}_{n}}}.\]
    By consistency, the left-hand side converges to 1, so that the right-hand side must also converge to 1.\qed{}
\end{myproofbox}

The converse of Lemma~\ref{lemm:implication} is not necessarily true. However, since asymptotic loss efficiency is easier to prove than consistency, it is in our interest to find conditions for their equivalency. Proposition~\ref{prop:equiv} illustrates two such cases.

\begin{proposition}[\cite{shao_1997}]\label{prop:equiv}
    Suppose H1, \(p_{n}/n\to 0\), and that \(\Tcal\) is non-empty for all but finitely many \(n\).
    \begin{enumerate}
        \item If \(|\Tcal|=1\) for all but finitely many \(n\), then consistency is equivalent to efficiency in the sense of Definition~\ref{def:consistency97}.
        \item If \(|\Tcal|\geq 2\) and \(p_{n}(\alpha^{*}_{n})\not\xrightarrow{\prob}\infty\), then consistency is equivalent to efficiency in the sense of Definition~\ref{def:consistency97}.
    \end{enumerate}
\end{proposition}
\begin{myproofbox}
    \textit{Proof: }
    From Lemma~\ref{lemm:implication}, it remains to show that, under the given conditions, asymptotic loss efficiency implies consistency. We show the contrapositive:

    \noindent1.\quad Suppose that \(\hat{R}_{n}\) is not consistent. By Proposition~\ref{prop:Ropt}, \(\alpha^{*}_{n}\) must be the correct model in \(\Tcal\) minimizing \(R_{n}\). Therefore, \(\Loss{\alpha^{*}_{n}} = (1/n)\normsq{H_{\alpha}\e}\), and
    \[\Ep{\Loss{\alpha^{*}_{n}}} = \frac{1}{n}\sigma^{2}p_{n}(\alpha^{*}_{n})\leq \frac{1}{n}\sigma^{2}p_{n}\to 0 \quad\text{as }n\to\infty\]
    by assumption. We have shown that \(\Loss{\alpha^{*}_{n}}\xrightarrow{L_{1}} 0\), which implies \(\Loss{\alpha^{*}_{n}}\xrightarrow{\prob} 0\).

    On the other hand, since \(\hat{R}_{n}\) is not consistent, there must exist \(\alphatilde_{n}\neq\alpha^{*}\) for infinitely many \(n\) such that \(\prob\set{\alphahat{}_{n} = \alphatilde_{n}} \neq 0\). Notice that, since \(\Tcal=\set{\alpha^{*}}\), it must be the case that \(\alphatilde_{n}\in\Tcal^{c}\). We have the following:
    \[\Loss{\alphahat{}_{n}}\geq \ind{\alphahat{}_{n} = \alphatilde_{n}}\Loss{\alphatilde_{n}} = \ind{\alphahat{}_{n} = \alphatilde_{n}}\paren{\frac{1}{n}\normsq{H_{\alphatilde_{n}}\e} + \frac{1}{n}\normsq{M_{\alpha}\X\bbeta}}.\]
    By assumption \textbf{H1}, the latter expression cannot not converge to 0. We conclude that the ratio \(\Loss{\alphahat{}_{n}}/\Loss{\alpha^{*}}\not\xrightarrow{\prob} 1\).

    \noindent2.\quad Suppose again that \(\hat{R}_{n}\) is not consistent. Since \(\Tcal\) contains at least two models, there must exist \(\alphatilde_{n}\in\Tcal\) such that \(\alphatilde_{n}\neq \alpha^{*}\) and \(\prob\set{\alphahat{}_{n} = \alphatilde_{n}}\not\to 0\). Hence,
    \[\frac{\Loss{\alphahat{}_{n}}}{\Loss{\alpha^{*}_{n}}} - 1 \geq \paren{\frac{\Loss{\alphatilde{}_{n}}}{\Loss{\alpha^{*}_{n}}} - 1}\ind{\alphahat{}_{n} = \alphatilde_{n}} = \paren{\frac{\normsq{H_{\alphatilde_{n}}\e}}{\normsq{H_{\alpha^{*}_{n}}\e}} - 1}\ind{\alphahat{}_{n} = \alphatilde_{n}}\not\xrightarrow{\prob}0.\]\qed{}
\end{myproofbox}

\subsection{A result on the leave-one-out}\label{sec:loo}
\renewcommand{\Acal}{\mathcal{A}}
\renewcommand{\Tcal}{\mathcal{T}}

Having established some essential results in the previous section, we now turn our attention to a particular variant of cross-validation, namely the leave-one-out. For this section, we will only consider the case where the set \(\Acal_{n}=:\Acal\) and all its elemets are constant across all \(n\geq 1\). That is, the candidate models are not changed by the number of observations.

The leave-one-out cross-validation method (otherwise known as delete-1 CV) consists in estimating a model using the data with one point removed, and then evaluating our estimate on the single removed point. This procedure is repeated for each data point and the results are averaged out onto a single loss estimate \(\loocv{\alpha}\) of \(R_{n}(\alpha)\). Formally, we define the leave-one-out loss estimator for a model \(\alpha\in\Acal\) to be 
\[\loocv{\alpha} := \frac{1}{n}\sum_{i=1}^{n}\paren{(y_{i} - \x_{i\alpha}^{\top}\bbetahat_{\alpha}^{(i)})}\qquad\text{with }\bbetahat_{\alpha}^{(i)} = \paren{\sum_{i\in[n]\setminus\set{i}}\x_{i\alpha}\x_{i\alpha}^{\top}}^{-1} \sum_{i\in[n]\setminus\set{i}} y_{i}\x_{i\alpha}.\]
The leave-one-out is a very popular tool for linear models due to its low computational cost. The following proposition shows that it is not necessary to fit all \(n\) coefficient vectors \(\bbetahat_{\alpha}^{(i)}\): it suffices to fit the model on the complete dataset just once. The proof uses the Sherman-Morrison inversion formula and will not be presented here.

\begin{proposition}
    For \(alpha\in\Acal\), the leave-one-out estimator \(\loocv{\alpha}\) satisfies the following equality:
    \[\loocv{\alpha}= \frac{1}{n}\sum_{i=1}^{n}\paren{\frac{y_{i}-\x_{i\alpha}^{\top}\bbetahat_{\alpha}}{1-h_{ii,\alpha}}}^{2},\]
    where \(h_{ii,\alpha} = \x_{i\alpha}^{\top}{(\X_{\alpha}^{\top}\X_{\alpha})}^{-1}\x_{i\alpha}\) denotes the \(i\)th leverage and \(\bbetahat_{\alpha}\) is the OLS estimator for model \(\alpha\) fitted on the whole data set.
\end{proposition}

Our goal in this section is to show some asymptotic properties of the leave-one-out as a criterion for model selection. The main result,~\ref{prop:shao93main} below, uses the following decomposition of \(\loocv{\alpha}\) in terms of \(R_{n}\) and other familiar quanitities.

\begin{lemma}[\cite{shao_1993}]\label{lem:lemmadecomp}
    \begin{equation}\label{eq:lemmadecomp}
    \loocv{\alpha} = \begin{cases}
        R_{n}(\alpha) + \sigma^{2} + \op{1} &\text{ if }\alpha\in\Tcal^{c}\\[2mm]
        \frac{1}{n}\normsq{M_{\alpha}\e} + \frac{2}{n}\sigma^{2}p(\alpha) + \op{n^{-1}} &\text{ if }\alpha\in\Tcal
    \end{cases}
    \end{equation}
\end{lemma}

\begin{myproofbox}
    \textit{Proof: }
    Using the Taylor expansion of \(1/{(1-x)}^{2} = 1+2x + O(x^{2})\), we have
    \[\frac{1}{\paren{1-\lev}^{2}} = 1 + 2\lev + \Op{\lev^{2}}.\]
    Thus,
    \begin{equation}
        \label{eq:xizeta}
        \loocv{\alpha} = \underbrace{\frac{1}{n}\sum_{i=1}^{n}\paren{y_{i}-\x_{i\alpha}^{\top}\bbetahat_{\alpha}}^{2}}_{\xi_{\alpha,n}} + \underbrace{\frac{1}{n}\sum_{i=1}^{n}\paren{2\lev + \Op{\lev^{2}}}\paren{y_{i}-\x_{i\alpha}^{\top}\bbetahat_{\alpha}}^{2}}_{\zeta_{\alpha,n}}
    \end{equation}
    Let \(\xi_{\alpha,n}\) and \(\zeta_{\alpha,n}\) denote the first and second terms in (\ref{eq:xizeta}), respectively. Note that
    \begin{align}
        \notag\xi_{\alpha,n} &= \frac{1}{n}\normsq{M_{\alpha}\X\bbeta + M_{\alpha}\e}\\
        \label{line:decomp}&= \frac{1}{n}\paren{\normsq{M_{\alpha}\e} + \normsq{M_{\alpha}\X\bbeta} + 2 \e^{\top}M_{\alpha}\X\bbeta}\\
        \label{line:decomp2}&=\frac{1}{n}\normsq{\e} + \frac{1}{n}\normsq{M_{\alpha}\X\bbeta} + \frac{1}{n}\normsq{H_{\alpha}\e} + \frac{2}{n}\e^{\top}M_{\alpha}\X\bbeta
        %\label{line:op1}&= \frac{1}{n}\normsq{\e} + \frac{1}{n}\normsq{M_{\alpha}\X\bbeta} + \op{1}.
    \end{align}
    From here, we emphasize four intermediate steps:
    \begin{enumerate}[i.]
        \item Using Markov's inequality, for \(\varepsilon>0\), \[\prob\set{\normsq{H_{\alpha}\e}\geq n\varepsilon}\leq \frac{\sigma^{2}p_{n}(\alpha)}{n\varepsilon}\to 0\] 
        \[\implies \frac{1}{n}\normsq{H_{\alpha}\e} = o_{\prob}(1).\]
        \item Since \(M_{\alpha}\) is a projection matrix, \(\normsq{M_{\alpha}\X\bbeta}\leq \normsq{\X\bbeta} = O_{\prob}(n)\), so that \[\Ep{\paren{\e^{\top} M_{\alpha}\X\bbeta}^{2}\mid\X} = \frac{4}{n^{2}}\sigma^{2}\normsq{M_{\alpha}\X\bbeta} = o_{\prob}(1).\] Combining the latter with \(\Ep{\e^{\top} M_{\alpha}\X\bbeta\mid\X} = 0\), we obtain that \[\frac{2}{n}\e^{\top}M_{\alpha}\X\bbeta = o_{\prob}(1).\]
        \item Combining i.\ and ii.\ with (\ref{line:decomp2}) yields \[\xi_{\alpha,n} = \frac{1}{n}\normsq{\e} + \frac{1}{n}\normsq{M_{\alpha}\X\bbeta} + o_{\prob}(1).\] Furthermore, since \(\normsq{\e} = O_{\prob}(n)\), we have that \(\xi_{\alpha,n} = O_{\prob}(1)\).
        \item Finally, since \(0<\lev<1\), \(2\lev + \Op{\lev^{2}}\leq\Op{\max_{i}\lev}\). Thus,
        \[\zeta_{\alpha,n}\leq\Op{\max_{i}\lev}\paren{\frac{1}{n}\sum_{i=1}^{n}\paren{y_{i} - \x_{i\alpha}^{\top}\bbetahat_{\alpha}}^{2}} = \Op{\max_{i}\lev}\xi_{\alpha,n}.\]
        From assumption \textbf{H3}, \(\zeta_{\alpha,n} = o_{\prob}(1)\xi_{\alpha,n} = o_{\prob}(1)\).
    \end{enumerate}
    It follows that 
    \[\loocv{\alpha} = \frac{1}{n}\normsq{e} + \frac{1}{n}\normsq{M_{\alpha}\X\bbeta} + o_{\prob}(1) \stackrel{(\mathrm{LLN})}{=} \sigma^{2} + \frac{1}{n}\normsq{M_{\alpha}\X\bbeta} + o_{\prob}(1).\]
    Noting that \(R_{n}(\alpha) = \frac{1}{n}\normsq{M_{\alpha}\X\bbeta} + o_{\prob}(1)\) yields the first case in (\ref{eq:lemmadecomp}).

    If \(\alpha\in\Tcal\), it is easy to see from (\ref{line:decomp}) that \(\xi_{\alpha,n} = 1/n\normsq{M_{\alpha}\e}\), Furthermore,
    \[\zeta_{\alpha,n} = \frac{2}{n}\sigma^{2}p(\alpha) + \op{1},\qquad\textcolor{red}{(?)}\]
    proving the second case.\qed{}
\end{myproofbox}

\begin{proposition}[\cite{shao_1993}]\label{prop:shao93main}
    Suppose that \(\Tcal\) is non-empty and let \(\alphahat{(1)}\) be the model minimizing \(\loocv{\alpha}\).
    \begin{enumerate}
        \item Under H1, H2, and H3, \[\lim_{n\to\infty}\prob\set{\alphahat{(1)}\in\Tcal^{c}}=0.\]
        \item For \(\alpha\in\Tcal\) with \(\alpha\neq\alpha^{*}\),\[\prob\set{\loocv{\alpha}\leq \loocv{\alpha^{*}}} = \prob\set{2\paren{p(\alpha) - p(\alpha^{*})}\sigma^{2} < \e^{\top}(H_{\alpha} - H_{\alpha^{*}})\e} + \op{1}.\] In particular, if \(\e\sim\Ncal(0_{n}, \sigma^{2}I_n)\), \[\prob\set{\loocv{\alpha}\leq \loocv{\alpha^{*}}} = \prob\set{2k < \chi^{2}(k)} + \op{1} > 0\] for \(k=p(\alpha) - p(\alpha^{*})\).
        \item If \(p(\alpha^*) < p\), \[\lim_{n\to\infty}\prob\set{\alphahat{(1)}=\alpha^{*}}\neq 1.\]
    \end{enumerate}
\end{proposition}

Before continuing with the proof, a few comments are in order. The first part of the proposition shows that, under the given conditions, the leave-one-out will select a correct model with probability approaching 1 as \(n\) approaches infinity. This is a relatively strong result, as it implies that the leave-one-out is reliable at excluding wrong models. However, parts 2 and 3 tell us that the leave-one-out is not consistent for selection in the sense of Definition~\ref{def:consistency97}: it selects overly complex correct models with non-vanishing probability. In other words, the leave-one-out is prone to overfitting.

An interpretation on what causes this behavior, as noted by~\textcite{shao_1993}, is that the leave-one-out places too much weight on the estimation and too little on the evaluation. If we let \(n_{1}\) denote the size of the fitting sets and \(n_{2}:=1-n_{1}\) the size of the validation sets, from~\ref{lem:lemmadecomp} we have that \(R_{n_{1}}(\alpha) = \sigma^{2}p(\alpha)/n_{1}\) for any correct model \(\alpha\in\Tcal\). Clearly, optimizing \(R_{n_{1}}(\alpha)\) over \(\Tcal\) becomes difficult for large \(n_{1}\): the larger \(n_{1}\), the closer \(R_{n_{1}}(\alpha)\) is to a flat line. With the leave-one-out, we are choosing the largest possible \(n_{1}= n-1\), making it difficult for the estimator to distinguish between correct models.

\begin{myproofbox}
    \textit{Proof of Proposition~\ref{prop:shao93main}: }

    \noindent1.\quad Let \(\alphabar\in \Tcal\) and \(\alphatilde\in\Tcal^{c}\). By, Lemma~\ref{lem:lemmadecomp}, we have that
    \begin{align*}
        \prob&\set{\loocv{\alphatilde}\leq \loocv{\alphabar}}\\
        &\qquad = \prob\Big\{\frac{1}{n}\sigma^{2}p(\alphatilde) + \frac{1}{n}\normsq{M_{\alphatilde}\X\bbeta} + \sigma^{2} + o_{\prob}(1) \leq \frac{1}{n}\normsq{M_{\alphabar}\e} + \frac{1}{n}\sigma^{2}p(\alphabar) + o_{\prob}(n^{-1})\Big\}\\
        &\qquad= \prob\set{\frac{1}{n}\sigma^{2}\paren{p(\alphatilde) - p(\alphabar)} + \sigma^{2} + \frac{1}{n}\normsq{M_{\alphatilde}\X\bbeta} - \frac{1}{n}\normsq{M_{\alphabar}\e}\leq o_{\prob}(1)}.
    \end{align*}
    From \textbf{H1}, the latter probability goes to zero as \(n\to\infty\). Therefore, \(\ind{\loocv{\alphatilde}\leq \loocv{\alphabar}} = o_{p}(1)\). We now observe that
    \[\prob\set{\alphahat{(1)}\in\Tcal^{c}} = \Ep{\ind{[\alphahat{(1)}\in\Tcal^{c}]}} = \Ep{\sum_{\alphatilde\in\Tcal^{c}}\prod_{\alpha\in\Acal} \ind{\loocv{\alphatilde}\leq \loocv{\alpha}}} \to 0.\]

    \noindent2.\quad The first part follows from Lemma 2.1 by algebraic manipulation. The second part follows by noting that, if \(\e\sim\Ncal(0_{n}, \sigma^{2}I_{n})\), then \[\frac{\e^{\top}}{\sigma}\paren{H_{\alpha} - H_{\alpha^{*}}}\frac{\e}{\sigma}\sim\chi^{2}\paren{\mathrm{tr}\paren{H_{\alpha}-H_{\alpha^{*}}}}.\]

    \noindent3.\quad It is easy to see that \(p(\alpha^{*}) = p\) if and only if \(\Tcal=\set{\alpha^{*}}\). Thus, if \(p(\alpha^{*}) < p\), there exists \(\alpha\in\Tcal^{c}\) with \(\alpha\neq \alpha^{*}\). The result then follows by part 2 above.\qed{}
\end{myproofbox}

%A subsequent result states that cross-validation is consistent if \(n_{v}/n\to 1\) as \(n\to\infty\), where \(n_{v}\) is the number of validation samples.



\subsection[A general perspective]{A General Perspective \protect\footnote{For this section, we allow the set of candidates \(\Acal\) to vary with \(n\), though we assume that it remains finite. To illustrate why this might be useful, we consider an example drawn from~\textcite{shao_1997}:\\ \indent If we wish to approximate a univariate regression function \(x\mapsto f(x)\) by a polynomial of degree at most \(p_{n}< n\), we may consider the models indexed by \(\Acal:=\set{\alpha_{d}:d\in[p_n]}\), with \(\alpha_{d} = \set{1,\ldots,d}\) and \(f_{\alpha_{d}}(x) = \beta_{0} + \beta_{1}x + \cdots + \beta_{d}x^{d}\). Clearly, the number of candidate models increases as more observations become available. Furthermore, the dimension of the optimal model \(\alpha^{*}_{n}\), for instance, may also increase with \(n\).}}\label{sec:gic}
\renewcommand{\Acal}{\mathcal{A}_{n}}
\renewcommand{\Tcal}{\mathcal{T}_{n}}

Our previous observations suggest that a smaller estimation set and a larger validation set might improve the performance of cross-validation procedures for model selection. In this section, we explore this idea from a different perspective, understanding cross-validation as a special case of a more general approach to loss estimation.

In the context of selection, overfitting occurs because our choice of empirical loss may underestimate the true loss for large models. The inclusion of irrelevant information can make the estimator \(\hat{R}_{n}\) ``hallucinate'' a signal that is not there. To avoid this problem, we may use \emph{penalization}: we modify our estimator \(\hat{R}_{n}\) to favour the choice of less complex models. Given some loss estimator \(\hat{R}_{n}\), we may define the corresponding \emph{penalized selection criterion} as
\[\hat{R}_{n}'(\alpha) = \hat{R}_{n}(\alpha) + \pen{\alpha}\]
for some penalty function \(\mathrm{pen}:\Acal\to\R\). 

A large portion of selection criteria in the literature can be reduced to a general penalized criterion with a penalty given by 
\[\mathrm{pen}_{\lambda_{n}}(\alpha) = \frac{1}{n} \lambda_{n} \sigmahat p_{n}(\alpha),\]
for some some estimator \(\sigmahat\) of \(\sigma^{2}\) and a sequence of real numbers \(\set{\lambda_{n}}_{n\geq 1}\) satisfying certain conditions. This type of penalty yields the \emph{Generalized Information Criterion}~(\cite{shao_1997}), defined below.

\begin{definition}\label{def:gic}
    We define the Generalized Informaton Criterion (GIC) loss estimator to be
    \[\Rhat{\lambda_{n}}{\alpha} := \frac{1}{n}\normsq{\y - \X_{\alpha}\bbetahat_{\alpha}} + \frac{1}{n}\lambda_{n}\sigmahat p_{n}(\alpha)\quad\text{for }\alpha\in\Acal,\]
    where \(\sigmahat\) is an estimator of \(\sigma^{2}\) and \(\lambda_{n}\) is a sequence of positive real numbers satisfying \(\lambda_{n}\geq 2\) and \(\lambda_{n}/n\to 0\).
\end{definition}

In what follows, we study some asymptotic properties of the GIC in two cases of interest: a constant \(\lambda_{n}\equiv 2\) and a growing \(\lambda_{n}\to\infty\).

\subsubsection{The case of \(\lambda_{n} \equiv 2\)}

\begin{theorem}[\cite{shao_1997}]\label{thm:97thm1}
    Suppose that \textbf{H4} holds and that \(\sigmahat\) is consistent for \(\sigma^{2}\). Let 
    \begin{enumerate}
        \item If \(|\Tcal|\leq1\) for all but finitely many \(n\), then \(\hat{R}_{n,2}\) is asymptotically loss efficient.
        \item Suppose that \(|\Tcal|> 1\) for all but finitely many \(n\). If there exists a positive integer \(m\) such that \(\Ep{y_{1} - \x_{1}^{\top}\bbeta}^{4m}<\infty\) and 
        \begin{equation}\label{eq:conditionsums}
            \sum_{\alpha\in\Tcal}\frac{1}{\paren{p_{n}(\alpha)}^{m}}\xrightarrow{n\to\infty} 0 \quad\text{or}\quad \sum_{\substack{\alpha\in\Tcal,\\ \alpha\neq\alpha^{*}}}\frac{1}{\paren{p_{n}(\alpha) - p_{n}(\alpha^{*})}^{m}}\xrightarrow{n\to\infty} 0,
        \end{equation}
        then \(\hat{R}_{n,2}\) is asymptotically loss efficient.
        \item Suppose that \(|\Tcal|>1\) for all but finitely many \(n\). 
        %Suppose, furthermore, that for any integer \(q\geq1\) and constant \(c>2\), 
        %\begin{equation}
        %    \label{eq:conditionQ}
        %    \liminf_{n\to\infty}\inf_{Q_{n}\in\mathcal{Q}_{n,q}}\prob\set{\normsq{Q_{n}\e} > c\sigma^{2}q} > 0,
        %\end{equation}
        %where \(\mathcal{Q}_{n,q}\) is the set of all projection matrices of rank \(q\). 
        If \(|\Tcal|\) is bounded,
        %or \(\Acal\) is embedded,
        then the condition that
        \begin{equation}
            \label{eq:conditionP}
            p_{n}(\alpha^{*}_{n})\to\infty\quad\text{or}\quad \min_{\substack{\alpha\in\Tcal,\\ \alpha\neq\alpha^{*}}}\paren{p_{n}(\alpha) - p_{n}(\alpha^{*})}\to\infty
        \end{equation}
        is necessary and sufficient for the asymptotic loss efficiency of \(\hat{R}_{n,2}\).
    \end{enumerate}
\end{theorem}

In short, Theorem~\ref{thm:97thm1} guarantees the asymptotic loss efficiency of \(\hat{R}_{n,2}\) in some cases where there exists at most one correct model with fixed dimension. In particular, the first part shows that \(\hat{R}_{n,2}\) asymptotically chooses the best-performing wrong model in the case that no correct model exists. If only one correct model exists in \(\Tcal\) and it has fixed dimension for all but finitely many \(n\), an application of Proposition~\ref{prop:equiv} in section~{\ref{sec:lmsetup}} yields consistency in selection. In other words, \(\hat{R}_{n,2}\) is able to identify the correct model among a set of incorrect models with probability tending to 1.

Parts 2.\ and 3.\ specify conditions for asymptotic loss efficiency in when multiple correct model exist. In these cases, \(\hat{R}_{n,2}\) performs well if no two correct models have fixed dimension. This is what conditions (\ref{eq:conditionsums}) and (\ref{eq:conditionP}) imply: they require that the dimensions of the models in \(\Tcal\) diverge, either absolutely or relative to the smallest correct model \(\alpha^{*}_{n}\). The following example illustrates this phenomenon:

\begin{myproofbox}
    \textbf{Example 2.1:} Suppose that \(\Acal = \Tcal = \set{\alpha_{1n}, \alpha_{2n}}\) with \(\alpha_{1n}\subset\alpha_{2n}\). Note that 
    \[\normsq{\y - \X_{\alpha}\bbetahat_{\alpha}} = \normsq{\e} - \normsq{H_{\alpha}\e}.\]
    Then, form Definition~\ref{def:gic}, \(\alphahat{}_{n} = \alpha_{1n}\) if and only if
    \begin{equation}\label{eq:examplecrit}
    \normsq{\paren{H_{\alpha_{2n}} - H_{\alpha_{1n}}}\e} < 2\sigmahat\paren{p_{2n}-p_{1n}},
    \end{equation}
    where \(p_{1n}\) and \(p_{2n}\) denote the dimensions of \(\alpha_{1n}\) and \(\alpha_{2n}\), respectively. If \(p_{1n}\to\infty\) and \(p_{2n} - p_{1n}\to\infty\), then
    \[\frac{\normsq{\paren{H_{\alpha_{2n}} - H_{\alpha_{1n}}}\e}}{p_{2n} - p_{1n}}\xrightarrow{\prob}\sigma^{2},\]
    so that (\ref{eq:examplecrit}) is satisfied with probability approaching 1 (by consistency of \(\sigmahat\)), and \(\Rhat{2}{\alpha}\) is consistent. If \(p_{1n}\to\infty\) but \(p_{2n} - p_{1n}\leq c\) for some \(c>0\), then \(p_{2n} / p_{1n}\to 1\), which yields \(\Loss{\alpha_{2n}}/\Loss{\alpha_{1n}} \to 1\). On the other hand, if \(\alpha_{1n}\) and \(p_{2n} - p_{1n}\not\to\infty\), then
    \[\frac{\Loss{\alphahat{}_{n}}}{\Loss{\alpha_{1n}}} = \ind{\alphahat{}_{n}=\alpha_{1n}} + \frac{\normsq{H_{\alpha_{2n}}\e}}{\normsq{H_{\alpha_{1n}}\e}}\ind{\alphahat{}_{n}=\alpha_{1n}}\]
    (see Prop.~\ref{prop:lossshao}). By Proposition~\ref{prop:Ropt}, \({\normsq{H_{\alpha_{2n}}\e}}/{\normsq{H_{\alpha_{1n}}\e}}\geq1\) almost surely. Hence,
    \[\frac{\Loss{\alphahat{}_{n}}}{\Loss{\alpha_{1n}}} = 1 + \paren{\frac{\normsq{H_{\alpha_{2n}}\e}}{\normsq{H_{\alpha_{1n}}\e}} - 1}\ind{\alphahat{}_{n}=\alpha_{1n}} = 1 + \frac{\normsq{\paren{H_{\alpha_{2n}} - H_{\alpha_{1n}}}\e}}{\normsq{H_{\alpha_{1n}}\e}} \stackrel{\mathrm{a.s.}}{>} 1.\]
    Thus, \(\Rhat{2}{\alpha}\) is not asymptotically loss efficient.    
\end{myproofbox}


%Note that condition (\ref{eq:conditionQ}) is satisfied if \(\e\sim\Ncal(0_{n}, \sigma^{2}I_{n})\). Condition (\ref{eq:conditionP}) is satisfied if \(\Acal\) does not contain two correct models with fixed dimension for all but finitely many \(n\).

Notice that these results resemble those presented in section~{\ref{sec:loo}} about the leave-one-out cross-validation estimator. Indeed, the correspondance between the leave-one-out and the GIC with \(\lambda_{n}\equiv 2\) will be discussed in section~{\ref{sec:cvgic}}.

%The proof of Theorem~\ref{thm:97thm1} uses the following decomposition, which we state without proof.
%\begin{proposition}[\cite{shao_1997}]\label{prop:97decomp1}
%    Suppose that \(\lambda_{n}=2\) for all \(n\geq 1\) and that \(\sigmahat\) is a consistent estimator of \(\sigma^{2}\). Then,
%    \[\Rhat{2}{\alpha} = \begin{cases}
%        \frac{1}{n}\normsq{e} + \frac{2}{n}\sigmahat p_{n}(\alpha) - \frac{1}{n}\normsq{H_{\alpha}\e}, &\text{if }\alpha\in\Tcal,\\[3mm]
%        \frac{1}{n}\normsq{e} + \Loss{\alpha} + \op{\Loss{\alpha}}, &\text{if }\alpha\in\Tcal^{c}.
%    \end{cases}\]
%\end{proposition}
%\begin{myproofbox}
%    \textit{Proof of Theorem~\ref{thm:97thm1}: }
%    \noindent1.\quad That \(\hat{R}_{n,2}\) satisfies asymptotic loss efficiency when \(\Tcal\) is empty follows immediately from Proposition~\ref{prop:97decomp1}. If \(Tcal\) contains exactly one model \(\alpha^{*}\), \textcolor{red}{the proof for this is given in the last paragraph of page 226. I don't understand it.}
%    \noindent2.\quad 
%    \qed{}
%\end{myproofbox}

\subsubsection{The case of \(\lambda_{n} \to \infty\)}

We now consider the GIC \(\hat{R}_{n,\lambda_{n}}\) with \(\lambda_{n}\to\infty\) as \(n\to \infty\). Unlike in the previous section, the following results do not require that \(\sigmahat\) be consistent for \(\sigma^{2}\).

\begin{theorem}[\cite{shao_1997}]\label{thm:97thm2}
    Suppose that \textbf{H1}-\textbf{H4} hold and that
    \begin{equation}\label{eq:310}
        \limsup_{n\to\infty}\sum_{\alpha\in\Tcal}\frac{1}{p_{n}{(\alpha)}^{m}}<\infty
    \end{equation}
    for some \(m\geq1\) with \(\Ep{e_{i}^{4m}}<\infty\).
    \begin{enumerate}
        \item If \(\lambda_{n}\to\infty\) and \(\lambda_{n}p_{n}/n \to 0\) are satisfied, then \(\hat{R}_{n,\lambda_{n}}\) is asymptotically loss efficient.
        \item Suppose that \(\lambda_{n}\to\infty\) and \(\lambda_{n}/n\to 0\). If there exists \(\alpha_{0}\in\Tcal\) with \(p_{n}(\alpha_{0})\) constant for all but finitely many \(n\), then \(\hat{R}_{n,\lambda_{n}}\) is consistent. 
    \end{enumerate}
\end{theorem}

As in the case of Theorem~\ref{thm:97thm1}, condition (\ref{eq:310}) restricts the asymptotic behavior of the size of correct models in \(\Tcal\). In contrast to the setup of of Theorem~\ref{thm:97thm1}, however, here we want correct models that eventually stop growing. In other words, Theorem~\ref{thm:97thm2} concerns itself with the case were we have correct models with fixed dimension.

It can be shown that condition (\ref{eq:310}) is satisfied whenever \(|\Tcal|\) is bounded or \(\Acal\) is embedded. It also implies that 
\begin{equation}\label{eq:310consequence}
    \max_{\alpha\in\Tcal} \frac{\normsq{H_{\alpha}\e}}{\lambda_{n}\sigmahat p_{n}(\alpha)}\xrightarrow{\prob} 0.
\end{equation}

The proof of Theorem~\ref{thm:97thm2} relies on the following decomposition, which we state without proof.

\begin{lemma}[\cite{shao_1997}]\label{prop:97decomp2}
    Suppose that \(\lambda_{n}=2\) for all \(n\geq 1\) and that \(\sigmahat\) is a consistent estimator of \(\sigma^{2}\). Then,
    \begin{equation}\label{eq:gicdecomp}
        \Rhat{\lambda_{n}}{\alpha} = \begin{cases}
            \frac{1}{n}\normsq{\e} + \frac{1}{n}\lambda_{n}p_{n}(\alpha)\sigmahat  - \frac{1}{n}\normsq{H_{\alpha}\e} &\text{if }\alpha\in\Tcal\\[3mm]
            \frac{1}{n}\normsq{\e} + \Loss{\alpha} + \frac{1}{n}p_{n}(\lambda_{n}\sigmahat - 2\sigma^{2}) + \op{\Loss{\alpha}} &\text{if }\alpha\in\Tcal^{c}
        \end{cases}
    \end{equation}
\end{lemma}

\begin{myproofbox}
    \textit{Proof of Theorem~\ref{thm:97thm2}: }From (\ref{eq:310consequence}), we have that 
    \begin{equation}\label{eq:shao97probnonopt}
        \frac{\normsq{H_{\alpha}\e}}{\lambda_{n}p_{n}(\alpha)} = \Op{\lambda_{n}^{-1}}.
    \end{equation}
    By an argument similar to the one in Example 2.1, it follows that
    \[\prob\set{\alphahat{n}\in\Tcal\text{ but }\alphahat{n}\neq\alpha^{*}_{n}}\to 0\]
    as \(n\to\infty\).

    For part 1., since \(\lambda_{n}p_{n}/n \to 0\) and from (\ref{eq:gicdecomp}),
    \[\Rhat{\lambda_{n}}{\alpha} = \frac{1}{n}\normsq{e} + L_{n}(\alpha) + \op{L_{n}(\alpha)}\]
    for \(\alpha\in\Tcal^{c}\). Additionally, if \(\Tcal\) is nonempty, 
    \[\Rhat{\lambda_{n}}{\alpha} = \op{L_{n}(\alpha)}\]
    for \(\alpha\in\Tcal\). We then have that the minimizer \(\alphahat{n}\) or \(\Rhat{\lambda_{n}}{\alpha}\) satisfies \(L_{n}(\alphahat{n})/L_{n}(\alpha^{*}_{n})\to 1\), with \(\alpha^{*}_{n}\) being the minimizer of the loss \(L_{n}\).

    For the second part, consistency follows immediately from (\ref{eq:shao97probnonopt}), \textbf{H1}, and Proposition~\ref{prop:Ropt} (that is, that the smallest correct model is the model minimizing \(L_n\)).
    \qed{}
\end{myproofbox}

\subsubsection{Cross-validation and the GIC}\label{sec:cvgic}

So far in this section, we have studied the properties of two general approaches to loss estimation with distinct properties, namely the GIC estimators with \(\lambda_{n}\equiv 2\) and \(\lambda_{n}\to\infty\). We will now connect these criteria with cross-validation methods, with the goal of ``inheriting'' some of former's properties to the latter.

\begin{theorem}[\cite{shao_1997}]\label{thm:97thm45}
    Suppose that \textbf{H1} to \textbf{H4} hold.

    \begin{enumerate}
        \item The assertions in Theorem~\ref{thm:97thm1} apply for the leave-one-out cross-validation estimator \(\hat{R}_{n}^{(1)}\).
        \item If \(d_{n}\leq n\) is chosen so that \(d_{n}/n\to1\) as \(n\to\infty\), then the delete-\(d_{n}\) cross-validation estimator \(\hat{R}_{n}^{(d_{n})}\) has the same asymptotic behavior as the GIC with \(\lambda\to\infty\). Specifically, if \[\frac{p_{n}}{n-d_{n}}\to 0\] and the splits are well ``balanced,'' then \(\hat{R}_{n}^{(d_{n})}\) is consistent in selection whenever \(\Acal\) contains at least one correct model with fixed dimension.
    \end{enumerate}
\end{theorem}

The conditions on \(d_{n}\) are important. Returning to the notation from the introduction, we can write \(n_{1}:=n-d_{n}\) for the size of estimation samples and \(n_{2}:=d_{n}\) for the size of validation samples. The conditions in Theorem~\ref{thm:97thm45} 2.\ can be written as 
\[\frac{n_{2}}{n}\to 1\quad\text{and}\quad \frac{p_{n}}{n_{1}}\to 0.\]
If \(p_{n}\) is fixed for large enough \(n\), we can equivalently write
\begin{equation}\label{eq:lmsplitcond}
    \frac{n_{2}}{n_{1}}\to\infty\quad\text{and}\quad n_{1}\to \infty.
\end{equation}
This confirms our conjecture from section~{\ref{sec:loo}}, where we argued that a larger validation size was necessary for cross-validation methods to be able to discriminate among correct models. Indeed, (\ref{eq:lmsplitcond}) shows that the validation size must be the dominating.

This is a major result in our investigation that can guide our intuition and inform choice of estimators. From a practical viewpoint, however, it might seem discouraging. One of the great appeals of the leave-one-out is its accessibility and exceptionally low computational cost. The delete-\(d\) approach, on the other hand, is less compelling: there is no general shortcut as there is for the leave-one-out, and, with a dominating validation size, the number of necessary model fittings can grow with \(n\) at an absurdly large rate. Fortunately, a result in the following section suggests that, as far as consistency goes, this might not always be the case. Moreover, in Section~\ref{sec:simulations}, we will explore the performance of more common and more feasible cross-validation methods, such as the \(k\)-fold.



\section{Selection of Nonparametric Procedures}\label{sec:yang}

\subsection{Setup}

In statistical learning, we are oftentimes more interested in finding a practical means for prediction rather than a precise description of the data-generating mechanism. In these cases, where the goal is optimal predictive performance, the notion of a ``true'' or ``correct'' model becomes less meaningful. Indeed, for many kinds of nonparametric estimators, it is possible to establish inequalities of the form
%\footnote{Here, \(\norm{\cdot}_{2}\) denotes the \(L_{2}[0,1]\) norm given by \(\norm{f}_{2} = \paren{\int |f|^{2}\,d\lambda}^{1/2}\).}
\[\sup_{f\in\Fcal}\E{\normsq{f - \hat{f}_{n}}} \leq C\psi_{n}^{2}\]
for certain constants \(C\), positive sequences \(\psi_{n}\to 0\), and classes of functions \(\Fcal\) (see~\cite{tsybakov_introduction_2009}). These inequalities imply that the risk is guaranteed to approach 0 as n increases, and therefore, unlike in linear models, model specification is less of a concern (although the inclusion/exclusion of relevant covariates remains important). 

The problem of selecting a nonparametric estimator of the regression function, then, focuses more on the rates of convergence \(\psi_{n}\) of each procedure. In this section, we will consider the simplified scenario of selecting between 
two regression procedures, denoted \(\delta_{1}\) and \(\delta_{2}\), that yield estimators \(\hat{f}_{n, 1}\) and \(\hat{f}_{n, 2}\) of the regression function \(f\).

\begin{definition}
    Let \(L_{n}\) be a loss function. We say \(\delta_{1}\) is \emph{asymptotically better} than \(\delta_{2}\) under \(L_{n}\) if, for \(0<\varepsilon<1\), there exists \(c_{\varepsilon}>0\) such that
    \[\prob\set{\Loss{\fhat{n}{2}}\geq (1+c_{\epsilon})\Loss{\fhat{n}{2}} }\geq 1-\varepsilon\]
    for all but finitely many \(n\).

    Given that \(\delta_{1}\) is asymptotically better than \(\delta_{2}\), we say that a selection procedure is consistent if it selects \(\delta_{1}\) with probability tending to 1 as \(n\to\infty\).
\end{definition}

In what follows, we will study the asymptotic performance of two variations on the cross-validation method for selecting an estimator. First, we will show that cross-validation with a single data split, also known as the \emph{hold-out}, is consistent in selection under some conditions on how the split is performed. Afterwards, we will show that this result extends to the multiple-split case with majority vote.

\subsection{Single-split cross-validation (the \emph{hold-out})}

For this section, we analyze a single-split approach where the first \(n_1\) elements in \(\data\) are used as a training/estimation sample and the remaining \(n_2\) elements make up the validation sample. We assume that the estimators \(\fhat{n}{1}\) and \(\fhat{n}{2}\) converge exactly at rates \(\set{p_{n}}_{n\geq 1}\) and \(\set{q_{n}}_{n\geq 1}\) under the \(L_{2}[0,1]\) loss, respectively. In other words, we assume that
\[\norm{f - \fhat{n}{1}}_{2} = \Op{p_{n}} \quad\text{and}\quad \prob\set{\norm{f-\fhat{n}{1}} \geq c_{\varepsilon}p_{n}} \geq 1-\varepsilon\]
for all \(\varepsilon\in(0,1)\) and for some \(c_{\varepsilon}>0\), and similarly for \(\fhat{n}{2}\) and \(q_{n}\).

The hold-out loss estimator is defined by
\begin{equation}\label{def:holoss}
    \ho(\fhat{n}{j}) = \sum_{i=n_{1}+1}^{n}\paren{y_{i} - \fhat{n_{1}}{j}(\x_{i})}^{2}\quad\text{for }j=1,2.
\end{equation}
The selection procedure consists in selecting the learning method \(\delta_{j}\) whose estimator \(\fhat{n}{j}\) minimizes \(\ho\) for \(j\in\set{1,2}\). We write \(\fho\) to denote the estimator selected by \(\ho\).

To show the consistency of \(\ho\), we will establish a few assumptions. First, we will assume the existance of two positive sequences \(\set{A_{n}}_{n\geq1}\) and \(\set{M_{n}}_{n\geq1}\) such that 
\begin{equation}\label{eq:lpconditions}
\norm{f-\fhat{n}{j}}_{\infty} = \Op{A_{n}}\quad\text{and}\quad\frac{\norm{f-\fhat{n}{j}}_{4}}{\norm{f-\fhat{n}{j}}_{2}} = \op{M_{n}}
\end{equation}
for \(j=1,2\). These rates of convergence will be used in the proof of Theorem~\ref{thm:yangth1} below. Note that the supnorm contition in (\ref{eq:lpconditions}) is satisfied if the regression function \(f\) and the estimators \(\fhat{n}{j}\) are bounded.

In addition to the above, we will assume that one of \(\delta_{1}\) and \(\delta_{2}\) is asymptotically better than the other. Indeed, if the latter is not satisfied, choosing one over the other may be irrelevant.

\begin{theorem}[\cite{yang_2007}]\label{thm:yangth1}
    Suppose that the conditions established above hold. Suppose, furthermore, that
    \begin{enumerate}
        \item \(n_{1}\to\infty\) as \(n\to\infty\)
        \item \(n_{2}\to\infty\) as \(n\to\infty\)
        \item \(n_{2}M_{n_{1}}^{-4} \to \infty\) as \(n\to\infty\)
        \item \(\sqrt{n_{2}}\max(p_{n_{1}}, q_{n_{1}})/\paren{1+A_{n_{1}}}\to\infty \) as \(n\to\infty\)
    \end{enumerate}
    Then, the hold-out CV procedure is consistent.
\end{theorem}

A very detailed proof of this result is given in~\textcite{yang_2007}, so it will be skipped here. We illustrate the conditions of Theorem~\ref{thm:yangth1} via an ideal-scenario example.

\begin{myproofbox}
    \textbf{Example: } Suppose that \(\fhat{n}{1}\) and \(\fhat{n}{2}\) are two nonparametric estimators with rates of convergence \(p_{n}=O\paren{n^{-4/9}}\) and \(q_{n}=O\paren{n^{-1/3}}\), respectively. Suppose that (\ref{eq:lpconditions}) is satisfied with \(A_{n} = O(1)\) and \(M_{n}=O(1)\). If we choose splits such that \(n_{1}\to\infty\) and \(n_{2}\to\infty\) as \(n\to\infty\), then \(n_{2}M_{n_{1}}^{-4}\) is clearly satisfied and 
    \[\frac{\sqrt{n_{2}}\max(p_{n_{1}}, q_{n_{1}})}{1+A_{n_{1}}} \geq \frac{n_{2}^{1/2}}{n_{1}^{1/3}}\to\infty \]
    is satisfied if \(n_{1}=o\paren{n_{2}^{3/2}}\). In other words, it is possible for the estimation size \(n_{1}\) to be dominating.

    On the other hand, if at least one of \(\fhat{n}{1}\) and \(\fhat{n}{2}\) has a parametric rate of convergence \(O(n^{-1/2})\), then
    \[\sqrt{n_{2}}\max(p_{n_{1}},q_{n_{1}})\geq \paren{\frac{n_{2}}{n_{1}}}^{1/2}\to\infty\]
    is satisfied whenever \(n_{2}/n_{1}\to\infty\). This agrees with the conclusion from Section~\ref{sec:lm}, in which we showed that cross-validation is often consistent if the validation size dominates.
\end{myproofbox}

\subsection{Voting cross-validation with multiple splits}

The majority-vote cross-validation method proceeds as follows:\footnote{The procedure desctibed here is theoretical in nature. In practice, we would not compute the hold-outs for all permutations of the data.} for each permutation \(i\mapsto\pi(i)\) of the data, we compute the estimators \(\fhat{n_{1}}{1}\) and \(\fhat{n_{1}}{2}\) using the first \(n_{1}\) data points,
\[\data^{E_{1}} = \set{\paren{y_{\pi(1)}, \x_{\pi(1)}}, \ldots,\paren{y_{\pi(n_1)}, \x_{\pi(n_1)}}},\]
as the training sample and the remaining \(n_{2}=n-n_{1}\) elements as the validation sample. We then find the estimator that minimizes the hold-out loss
\[\hat{L}_{\pi}(\fhat{n}{j}) = \sum_{i=n_{1}+1}^{n}\paren{y_{\pi(i)} - \fhat{n_{1}}{j}\paren{\x_{\pi(i)}}}^{2}\qquad \text{for }j=1,2.\]
The chosen estimator is the one favored by the majority of the permutations. More formally, we define 
\[\tau_{\pi} = \ind{\hat{L}_{\pi}(\fhat{n}{1}) \leq \hat{L}_{\pi}(\fhat{n}{2})}\]
We then define our selection criterion as follows:
\[\hat{f}_{n} = \begin{cases}
    \fhat{n}{1} &\text{if }\sum_{\pi\in\Pi}\tau_{\pi} \geq {n!}/{2},\\[2mm]
    \fhat{n}{2} &\text{otherwise,}
\end{cases}\]
where \(\Pi\) denotes the set of all permutations of \([n]\).

\begin{theorem}[\cite{yang_2007}]\label{thm:yangth2}
    Under the conditions of Theorem~\ref{thm:yangth1} and the condition that the data is iid, the majority-vote cross-validation method is consistent.
\end{theorem}

\begin{myproofbox}
    \textit{Proof: }
    Suppose that \(\delta_{1}\) is asymptotically better than \(\delta_{2}\). For \(\pi\in \Pi\), we have that
    \[\prob\set{\hat{L}_{\pi}\paren{\fhat{n}{1}} \leq \hat{L}_{\pi}\paren{\fhat{n_{1}}{2}}} = \Ep{\tau_{\pi}} \stackrel{(*)}{=} \Ep{\frac{1}{n!}\sum_{\pi\in\Pi}\tau_{\pi}}.\]
    The equality at \((*)\) follows from the fact that the data are iid, hence exchangeable, and thus the \(\tau_\pi\) are identically distributed. By Theorem~\ref{thm:yangth1}, the right-hand side converges to 1 as \(n\to\infty\). Since the average \(1/n! \sum_{\pi}\tau_{\pi}\) is almost surely at most 1, it follows that \(1/n! \sum_{\pi}\tau_{\pi} \to 1\) in probability, and the majority-vote cross-validation method is consistent.\qed{}
\end{myproofbox}

The proof of Theorem~\ref{thm:yangth2} does not require using the entire set \(\Pi\) of permutations for the majority vote. In fact, Theorem~\ref{thm:yangth1} establishes that even a single data split suffices for consistency, provided the splitting conditions are met. Moreover, \textcite{yang_2007} presents a counterexample demonstrating that these conditions are not merely sufficient but necessary, hence showing that the number of splits does not affect consistency. In other words, multiple splits in cross-validation cannot rescue an inconsistent single-split procedure.

%A natural question, then, is: if multiple splits do not improve consistency, what is their benefit? This will be explored in a simulation later on.

\subsection{Some remarks}

The theoretical results presented in this chapter highlight important distinctions between cross-validation for parametric and nonparametric procedures. Unlike Shao's results for parametric model selection, where the validation set must asymptotically dominate the training set to achieve consistency, our analysis shows that for nonparametric procedures, the training set can be dominant provided certain convergence conditions are satisfied. This contrast emphasizes that the optimal splitting strategy depends critically on the nature of the procedures being compared.

Cross-validation proves particularly useful for selection when comparing estimators with different convergence rates, as demonstrated in our theorems. The consistency of both single-split and majority-vote methods suggests that cross-validation can reliably identify asymptotically superior procedures under appropriate conditions on the \(L_{2}\), \(L_4\), and \(L_{\infty}\) norms of the estimation error. Not unlike the results in~\textcite{shao_1993}, however, the results in this section also indicate that leave-one-out cross-validation, where $n_1 = n-1$ and $n_2 = 1$, is generally inadequate for consistent selection since the validation size condition $n_2 \to \infty$ is violated.

While this section focused the voting approach, it is worth noting that the more common averaging approach (described, for example, in~\ref{sec:cv}) should, in theory, retain more information from the data. From a consistency perspective, \textcite{yang_2007} hypothesizes that both approaches are likely to be equivalent: if a majority of the permutations favour \(\fhat{n}{1}\), say, with high probability, then it is also likely that the average \((1/n!)\sum_{\pi\in\Pi}\hat{L}_{\pi}(\fhat{n}{1})\) will be smaller than that of \(\fhat{n}{2}\).

Several practical considerations emerge from this analysis, including the optimal choice of splitting ratios and the relative merits of k-fold procedures versus single splits. While our theoretical framework provides guidance on asymptotic properties, the finite-sample performance of these methods under various conditions remains an important question. These practical aspects, along with empirical comparisons between different cross-validation variants, will be addressed through simulation studies in a subsequent chapter.~\ref{sec:simulations}


\section{Aggregation}

As is generally the case in statistics, the need for model selection stems from an uncertainty or lack of knowledge about the system being studied. And while selection procedures may give us improved confidence on our estimation endeavours, it certainly will not cure our ignorance. For instance, without any means of verifying underlying hypotheses (say, linearity of \(f\) for linear models, or its membership to a Soblovev class for projection estimators), we have no guarantee that a single selected procedure will reliably yield good predictions. Moreover, selection may not even be helpful if the models being considered are hard to distinguish or if no clear winner exists among them. 

As stated in the Introduction, a good alternative to selection is \emph{aggregation}: the combining of multiple candidate models into a single estimator.
Aggregation of multiple estimators consists in combining them via a weighted average. In fact, as will be shown below, model selection can be seen a special case of this broader framework, where the computed ``weighted average'' has weights equal to 0 for all but one candidate model. 

This section explores some perspectives through which aggregation schemes can be analyzed and presents asymptotic results on a particular aggregate estimator drawn from \textcite{bunea_2007}.

\subsection{Setup}

As before, we consider independent pairs in \(\data := \set{\paren{y_{i}, \x_{i}}:i\in [n]}\) satisfying the conditions established in Section~\ref{sec:setup}. Suppose that we have \(M\) candidate estimators of the regression function, denoted \(\fhat{n}{1}, \fhat{n}{2}, \ldots, \fhat{n}{M}\). Given a set \(\Lambda\subset\R^{M}\) of admissible weights, we combine the estimators into an \emph{aggregate} \(\ftilde{\lambdahat{}}\) given by
\[\ftilde{\lambdahat{}} = \sum_{j=1}^{M}\lambdahat{j} \fhat{n}{j},\]
with \(\lambdahat{}:=\paren{\lambdahat{1}, \ldots, \lambdahat{M}}\in \Lambda\) chosen to satisfy some optimality criteria.

We establish the following assumptions for this section.

\begin{quotation}
    \noindent\textbf{H4.1:}\quad The residuals \(\epsilon_{i}\) have a normal distribution \(\Ncal(0, \sigma^{2})\) for \(\sigma^{2}<\infty\).
    
    \vspace{3mm}
    
    \noindent\textbf{H4.2:}\quad The regression funcion \(f\) and the base estimators \(\fhat{n}{1}, \fhat{n}{2}, \ldots, \fhat{n}{M}\) belong to the space \(L_{\infty}([0,1], \mu_{\x})\).
\end{quotation}

Both assumptions grant well-behaved estimators and allow for the application of certain minimax results relating, in particular, to the Kullback-Liebler divergence between the distributions of estimators in the class \(\Fcal_{0}\).

\subsubsection{Four types of aggregation}\label{sec:buneaschemes}

There are four main aggregation schemes that are treated in the literature. Each scheme is characterized by a different set \(\Lambda\) of admissible weights, and they are all suitable for distinct use cases. The schemes are:
\begin{itemize}
    \item Model Selection Aggregation (MS): Only one estimator is selected among the candidates. We take \(\Lambda_{\mathrm{MS}}\) to be the standard basis on \(\R^{M}\).
    \item Linear Aggregation (L): The aggregate \(\ftilde{\lambdahat{}}\) is chosen among all linear combinations of the estimators. We let \(\Lambda_{\mathrm{L}} = \R^{M}\).
    \item Convex Aggregation (C): The aggregate \(\ftilde{\lambdahat{}}\) is chosen among all convex combinations of the estimators. That is, \[\Lambda_{\mathrm{C}} = \set{\lambda\in\R^{M}:\lambda\geq 0, \sum_{j=1}^{M}\lambda_{j} = 1}.\]
    \item Subset Selection (S): Given a positive integer \(D\leq M\), at most \(D\) estimators from the candidates are selected and combined. That is, \[\Lambda_{\mathrm{S}} = \set{\lambda\in\R^{M}:\lambda\text{ has at most \(D\) non-zero entries}}.\]
    To denote the number of nonzero entries in a vector \(\lambda\), we may use the notations \(M(\lambda)\) and \(\norm{\lambda}_{0}\) interchangeably.
\end{itemize}

Notably, mentioned before, model selection can be viewed from this framework as a particular type of aggregation. Each of this schemes may perform differently on different tasks, and 

\subsubsection{Evaluating the aggregate}

In an ideal scenario, we would like to select a weights vector \(\lambda^*\) that minimizes the largest possible expected error on a class of functions \(\Fcal\) containing \(f\). That is, we would like to find \(\lambda^*\) satisfying 
\begin{equation}\label{eq:minimax}
    \sup_{f\in\Theta}\E\normsq{f-\ftilde{\lambda^*}}_{2} = \inf_{\lambda\in\Lambda}\sup_{f\in\Theta}\E\normsq{f-\ftilde{\lambda}}_{2}.
\end{equation}
This is known as \emph{minimax} extimation. 
However, there is no obvious way to compute the expectation \(\E\normsq{f-\ftilde{\lambdahat{}}}_{2}\) for an arbitrary \(f\in\Theta\), and so the minimax approach is not feasible in practice. The next best thing, then, would be to obtain weights \(\lambdahat{}\) that perform at least as good as \(\lambda^*\) in (\ref{eq:minimax}) plus some small, ideally vanishing remainder \(\Delta_{n,M}\). That is, we seek \(\lambdahat{}\) such that
\begin{equation}\label{eq:oracleineq}
    \E\norm{f - \ftilde{\lambdahat{}}}_{2} \leq \inf_{\lambda\in\Lambda}\E\norm{f - \ftilde{\lambda}}_{2} + \Delta_{n,M},
\end{equation}
regardless of what \(f\) is. With this approach in mind, we now introduce the notion of an \emph{oracle}.

\begin{definition}[adapted from~\cite{tsybakov_introduction_2009}]\label{def:oracle}
    Suppose that there exists \(\lambda^{*}\in\Lambda\) such that 
    \[\E\normsq{f-\ftilde{\lambda^{*}}}_{2} = \inf_{\lambda\in\Lambda}\E\normsq{f-\ftilde{\lambda}}_{2}.\]
    The function \(f\mapsto \ftilde{\lambda^{*}}\) is called the oracle of aggregation under the \(L_{2}\) norm.

    The inequality at (\ref{eq:oracleineq}) is called an oracle inequality, and we say that the aggregate \(\ftilde{\lambdahat{}}\) mimics (or is adaptive to) the oracle if (\ref{eq:oracleineq}) is satisfied for the smallest possible \(\Delta_{n,M}>0\) independent of \(f\).
\end{definition}

As is suggested in the latter definition, the remainder \(\Delta_{n,M}\), also known as the \emph{rate of convergence} of \(\ftilde{\lambdahat{}}\), is central to the evaluation of an aggregate's suitability. Both lower and upper bounds on these rates of convergence can be theoretically found for each of the above-mentioned schemes, and these bounds can guide us towards optimal choices of \(\lambdahat{}\). The lower bounds will be particularly useful since, from Definition~\ref{def:oracle}, we are mainly interested in the smallest possible rate \(\delta_{n,M}\)

\begin{definition}[\cite{tsybakov_introduction_2009}]
    Let \(\Lambda\subset\R^{M}\) be a set of admissible weights and let \(\Fcal\) and \(\Fcal'\) be classes of Borel-measurable functions on \([0,1]\) with \({\{\ftilde{\lambda}\}}_{\lambda\in\Lambda}\subset\Fcal'\). A sequence \(\set{\psi_{n,M}}_{n,M\geq1}\) of positive numbers is called an optimal rate of convergence if there exist constants \(c, C>0\) such that, for any \(n\geq 1\), 
    \begin{equation}\label{eq:orcupper}
        \sup_{f\in\Fcal}\paren{\E\normsq{f-\ftilde{}}_{2} - \inf_{\lambda\in\Lambda}\normsq{f - \ftilde{\lambda}}_{2}}\leq C\psi_{n,M}
    \end{equation}
    for some aggregate estimator \(\ftilde{}\) of \(f\), and 
    \begin{equation}\label{eq:orclower}
        \sup_{f\in\Fcal}\paren{\E\normsq{f - T_{n}} - \inf_{\lambda\in\Lambda}\normsq{f - \ftilde{\lambda}}}\geq c\psi_{n,M}     
    \end{equation}
    for any data-dependent estimator \(T_{n}\) of \(f\).
\end{definition}

We now state optimal rates of convergence for the four aggregation schemes presented above. Theorem~\ref{prop:buneath5.1} below relies on the following assumptions:

\begin{quotation}
\noindent\textbf{H4.3:}\quad There exists \(S\subset{[0,1]}^{p_{n}}\) such that \(\mu_{\x}\) has a bounded density \(g_{\x}\) w.r.t the Lebesgue measure satisfying \(g_{\x}(\z)>0\) for \(\z\in S\).

\vspace{3mm}

\noindent\textbf{H4.4:}\quad \(M\leq c_{0}n\) and \(\log(M)\leq c_{0}n\) for some \(c_{0}>0\).
\end{quotation}

In the following statement, we use the notation \(a_{n}\asymp b_{n}\) for sequences \(a_{n}, b_{n}\) to denote that \(cb_{n}\leq a_{n}\leq Cb_{n}\) for some constants \(0<c\leq C<\infty\).

\begin{theorem}[\cite{bunea_2007}]\label{prop:buneath5.1}
    Suppose that \textbf{H4.1} to \textbf{H4.4} hold. For \(\Lambda_{\mathrm{MS}}\), \(\Lambda_{\mathrm{L}}\), \(\Lambda_{\mathrm{C}}\), and \(\Lambda_{\mathrm{S}}\) as defined in Section~\ref{sec:buneaschemes}, the inequality at (\ref{eq:orclower}) is satisfied for the rates given by
    \begin{equation}\label{eq:rates}
        \psi_{n,M}\asymp\begin{cases}
            \log(M)/n &\text{if }\Lambda = \Lambda_{\mathrm{MS}},\\[1mm]
            M/n &\text{if }\Lambda = \Lambda_{\mathrm{L}},\\[1mm]
            M/n &\text{if }\Lambda = \Lambda_{\mathrm{C}}\text{ and }M\leq\sqrt{n},\\[1mm]
            \sqrt{\log\paren{1+M/\sqrt{n}}/n}&\text{if }\Lambda = \Lambda_{\mathrm{C}}\text{ and }M>\sqrt{n},\\[1mm]
            (D\log(1+M/D)/n) &\text{if }\Lambda = \Lambda_{\mathrm{S}},
        \end{cases}
    \end{equation}
    with \(M \log(M/D+1) \leq n \) and \(M \geq D\) in the case of Subset aggregation (S).
\end{theorem}

The proof of Theorem~\ref{prop:buneath5.1} is beyond the scope of this report. A proof in the case of a random design (being considered here) can be found in~\textcite{tsybakov_ora} and relies on a result on the -Liebler divergence between the distributions of two estimators vergence stated in page 99 of~\textcite{tsybakov_introduction_2009}.

The four general aggregation schemes were introduced here as common staples in the litterature. A natural question to ask is when and why should we use one scheme over the other. This problem remains open~\cite{bunea_2007}, and it is generally difficult to compare these procedures. In fact, results that achieve the oracle adaptability in the sense of Definition~\ref{def:oracle} and (\ref{eq:oracleineq}) are rather rare or restricted in scope. Oftentimes, results attain a relaxation of (~\ref{eq:oracleineq}) is given in the form
\begin{equation}\label{eq:oraclerelax}
    \E\norm{f - \ftilde{\lambdahat{}}}_{2} \leq (1+\varepsilon)\inf_{\lambda\in\Lambda}\E\norm{f - \ftilde{\lambda}}_{2} + \Delta_{n,M},
\end{equation}
for some small \(\varepsilon>0\) independent of \(f\). This is the goal that we will adopt in this section.

\subsection{The penalized least-squares approach}

So far, we have studied properties that can inform our construction of an appropriate aggregate \(\ftilde{\lambdahat{}}\) but we have yet to actually construct such an estimator. In this section, rather that focusing on a single one of the aggregation schemes given above, we examine a penalized least squares approach drawn from~\textcite{bunea_2007}. We will consider aggregates \(\ftilde{\lambdahat{}}\) with weights satisfying

\begin{equation}\label{eq:weights}
    \lambdahat{}=\argmin_{\lambda\in\Lambda}\paren{\frac{1}{n}\normsq{\y_{n} - \ftilde{l\lambda}(\X_{n})} + \mathrm{pen}(\lambda)}
\end{equation}

for some penalty \(\mathrm{pen}(\lambda)\). We will show that, for an appropriate choice of \(\mathrm{pen}(\lambda)\), such an estimator gets close to all rates in~\ref{prop:buneath5.1} in the sense of (\ref{eq:oraclerelax}).

\begin{definition}\label{def:bic}
    For \(\lambda\in\Lambda\), let \(M(\lambda) := \norm{\lambda}_{0}\) (i.e., the number of non-zero coefficients in \(\lambda\)) and write
    \[L(\lambda) = 2\log\paren{\frac{eM}{\max(M(\lambda), 1)}}.\]
    For \(a>0\), we define the Bunea-Tsybakov-Wegkamp BIC-type penalty to be
    \[\penBIC{\lambda} := \frac{2\sigma^{2}}{n}M(\lambda)\paren{1+\frac{2+a}{1+a}\sqrt{L(\lambda)} + \frac{1+a}{a}{L(\lambda)}}.\]
    This penalty yields the BIC-type least-squares aggregate \(\ftilde{\mathrm{BIC}} := \ftilde{\lambdahat{\mathrm{BIC}}}\) with 
    \[\lambdahat{BIC}=\argmin_{\lambda\in\R^{M}}\set{\frac{1}{n}\normsq{\y - f_{\lambda}(\x)} - \penBIC{\lambda}}\]
\end{definition}

Theorem~\ref{thm:bunea31} below, which get us closer to a result of the type in~\ref{eq:oraclerelax} for the \(\ftilde{\mathrm{BIC}}\), relies on the two following lemmas, which are stated without proof:

\begin{lemma}\label{lemm:binombound}
    For positive integers \(m \leq M\),
    \[\binom{M}{m} \leq \paren{\frac{eM}{m}}^m.\]
\end{lemma}

\begin{lemma}[Adapted from~\textcite{BirgeMassart2001}]\label{lemm:birge}
    Let \(\Acal\) be an index set and let \(\mathrm{pen}_{0}\) be a penalty. Suppose that there exists a family of weight sets \(\set{\Lambda_{\alpha}}_{\alpha\in\Acal}\), a collection of integers \(\set{m_{\alpha}}_{\alpha\in\Acal}\), and a real sequence \(\set{p_{\alpha}}_{\alpha\in\Acal}\) such that \(M(\lambda) = m_{\alpha}\) and \(\mathrm{pen}_{0}(\lambda) = p_{\alpha}\) for all \(\lambda\in\Lambda_{\alpha}\). Suppose, furthermore, that there exists a collection of non-negative real numbers \(\set{L_{\alpha}}_{\alpha\in\Acal}\) satisfying 
    \begin{equation}\label{eq:conditionbirge1}
        \Sigma:=\sum_{\alpha\in\Acal}\exp\paren{-m_{\alpha}L_{\alpha}}<\infty.
    \end{equation}
    Let \(\theta\in(0,1)\) and \(K>2-\theta\). If there exists a finite subset (possibly empty) \(\bar{\Acal}\subset\Acal\) such that, for all \(\alpha\in\Acal\setminus\bar{\Acal}\), 
    \begin{equation}\label{eq:conditionbirge2}
        p_{\alpha} \geq \frac{\sigma^2}{n}m_{\alpha}\paren{K + 2(2-\theta)\sqrt{L_{\alpha}} +2{\theta^{-1}}L_{\alpha}} =: Q_{\alpha}\qquad\text{whenever }\lambda\in\Lambda_{\alpha}.
    \end{equation}
        Then, the aggregate \(\ftilde{\lambdahat{}}\) corresponding to \(\mathrm{pen}_{0}\) as defined by  (\ref{eq:weights}) exists almost surely and satisfies
    \begin{align}
        \notag\paren{1-\theta}\E{\normsq{f - \ftilde{\lambdahat{}}}} \leq 
        \inf_{\alpha\in\Acal}&\set{\inf_{\lambda\in\Lambda_{\alpha}}\paren{\normsq{f - \ftilde{\lambda}}} + p_{\alpha} - \frac{\sigma^2}{n}m_{\alpha}}\\
        \notag&+ \sup_{\alpha\in\Acal}\set{Q_{\alpha} - p_{\alpha}}\\
        &+ \frac{\sigma^{2}}{n}m_{\alpha}\Sigma \paren{\paren{2-\theta}^{2}\paren{K+\theta-2}^{-1} + 2\theta^{-1}}
    \end{align}

\end{lemma}

Lemma~\ref{lemm:birge} may seem rather convoluted and abstract. However, it essentially tells us that the risk \(\E{\normsq{f - \ftilde{\lambdahat{}}}}\) can be upper-bounded if a suitable discretization of the admissible weights can be found. This utility will become apparent in the proof of the following theorem.

\begin{theorem}[\cite{bunea_2007}]\label{thm:bunea31}
    Assume that \textbf{H4.1} and \textbf{H4.2} hold. Then, for all \(a>0\), \(M\geq 2\), and \(n\geq 1\),
    \begin{align*}
        \E\normsq{\ftilde{\mathrm{BIC}} - f} &\leq (1+a)\inf_{\lambda\in\R^{M}}\set{\normsq{\ftilde{\lambda} - f} + \frac{\sigma^{2}}{n}\paren{5+\frac{2+3a}{a}{L(\lambda)}}M(\lambda)} + \frac{6\sigma^{2}{(1+a)}^{2}}{an(e-1)}
    \end{align*}

\end{theorem}

\begin{myproofbox}
    \textit{Proof: }Define \(\Lambda_{m}\) for each integer \(0\leq m\leq M\) as
    \[\Lambda_{m}:=\set{\lambda\in\R^{M} : M(\lambda) = m}\]
    and let \(\set{J_{m,k}}\) for \(k=1,\ldots,\binom{M}{m}\) be the collection of subsets all of \([M]\) such that \(|J_{m,k}| = m\). Define
    \[\Lambda_{m,k} :=\set{\lambda\in\Lambda_{m}:\lambda_{j}\neq 0 \iff j\in J_{m,k}}\]
    and note that \(\mathcal{P}_{m}:=\set{\Lambda_{m,k}:k=1,\ldots,\binom{M}{m}}\) forms a partition on \(\Lambda_{m}\), while \(\bigcup_{m}\mathcal{P}_{m}\) is a partition of \(\R^{M}\). Notice also that
    \begin{itemize}
        \item the function \(L(\lambda)\) from Definition~\ref{def:bic} is constant on each \(\Lambda_{m}\), \(0\leq m\leq M\), with\[L(\lambda) = 2\ln\paren{\frac{eM}{\max(m, 1)}} =: L_{m}\]
        \item trivially, the zero-norm \(M(\lambda)\) is a constant \(m\) on each \(\Lambda_{m}\), \(0\leq m\leq M\);
        \item the penalty \(\penBIC{\lambda}\) is constant on each \(\Lambda_{m}\), \(0\leq m\leq M\).
    \end{itemize}
    More formally, for \(0\leq m\leq M\) and \(k=1,\ldots,\binom{M}{m}\), we have that the images \(\penBIC{\Lambda_{m,k}} = \set{p_{m}}\) and \(L(\Lambda_{m,k})=\set{L_{m}}\) for some \(\set{p_{m}}_{m=0}^{M}\) and \(\set{L_{m}}_{m=0}^{M}\).
    
    Positioning ourselves for an application of Lemma~\ref{lemm:birge}, we let \(\Acal := \set{(m,k):m\leq M, k\leq \binom{M}{m}}\), \(K=2\), and \(\theta = a/(1+a)\) for some arbitrary \(a>0\). It is easy to see from the definition of \(\penBIC{\lambda}\) that condition (\ref{eq:conditionbirge2}) is satisfied with equality for all \((m,k)\in\Acal\).
    Furthermore, let \(\Sigma:=\sum_{\alpha\in\Acal}\exp\paren{-m_{\alpha}L_{\alpha}}\) and note that
    \begin{align}
        \notag\Sigma &= \sum_{m=1}^{M} \binom{M}{m}\paren{e^{\ln\paren{eM/m}}}^{-2m} = \sum_{m=1}^{M} \binom{M}{m}\paren{\frac{eM}{m}}^{-2m}\\
        \notag&\leq \sum_{m=1}^{M}\paren{\frac{eM}{m}}^{m}\paren{\frac{eM}{m}}^{-2m} = \sum_{m=1}^{M}\paren{\frac{m}{M}}^{m}e^{-m}&(\text{Lemma~\ref{lemm:binombound}})\\
        &\leq \sum_{m=1}^{M} e^{-m} \leq \frac{1}{e-1}.\label{line:buneaexp}
    \end{align} 
    Hence, condition (\ref{eq:conditionbirge1}) is also satisfied. We apply Lemma~\ref{lemm:birge} and obtain that
    \begin{align*}
        \paren{\frac{1}{1+a}}\E{\normsq{f - \ftilde{\mathrm{BIC}}}} &\leq 
        \inf_{(m,k)\in\Acal}\set{\inf_{\lambda\in\Lambda_{m}}\paren{\normsq{f - \ftilde{\lambda}}} + p_{m} - \frac{\sigma^2}{n}m}\\
        &\qquad\qquad + \sup_{(m,k)\in\Acal}\set{p_{m} - p_{m}}\\
        &\qquad\qquad + \frac{\sigma^{2}}{n}m\Sigma \paren{\paren{2-\paren{\frac{a}{1+a}}}^{2}{\paren{\frac{1+a}{a}}} + {\frac{2+2a}{a}}}\\
        &= \inf_{(m,k)\in\Acal}\set{\inf_{\lambda\in\Lambda_{m}}\paren{\normsq{f - \ftilde{\lambda}}} + p_{m} - \frac{\sigma^2}{n}m}\\
        &\qquad\qquad \frac{(1+a)\sigma^{2}}{an}\paren{\paren{\frac{2+a}{1+a}}^{2} +2}\Sigma.
    \end{align*}

    A simple argument can be made (using, for example, the quadratic formula on \(L_{m}\)) to show that
    \[n\penBIC{\lambda} - m\sigma^{2} = \sigma^{2}m\paren{1+2\paren{\frac{2+a}{1+a}}\sqrt{L_{m}} + 2\paren{\frac{1+a}{a}}L_{m}}\leq \sigma^{2}m\paren{5 + \frac{2+3a}{a}L_{m}}\]
    for any \(\Lambda_{m}\), \(m=0,\ldots,M\), and \(a>0\). Combining this with (\ref{line:buneaexp}),
    \begin{align*}
        \paren{\frac{1}{1+a}}\E{\normsq{f - \ftilde{\lambdahat{}}}}&\leq \inf_{(m,k)\in\Acal}\set{\inf_{\lambda\in\Lambda_{m}}\paren{\normsq{f - \ftilde{\lambda}}} + \frac{\sigma^{2}m}{n}\paren{5 + \frac{2+3a}{a}L_{m}}}\\[2mm]
        &\qquad\qquad + \frac{6\sigma^{2}{(1+a)}}{an(e-1)}\\
        &= \inf_{\lambda\in\R^{M}}\set{\normsq{\ftilde{\lambda} - f} + \frac{\sigma^{2}}{n}\paren{5+\frac{2+3a}{a}{L(\lambda)}}M(\lambda)} + \frac{6\sigma^{2}{(1+a)}}{an(e-1)}.
    \end{align*}
    \qed{}
\end{myproofbox}

Theorem~\ref{thm:bunea31} implies that the \(\ftilde{\mathrm{BIC}}\) aggregate satisfies the bounds in (\ref{eq:rates}).

\begin{corollary}[\cite{bunea_2007}]\label{cor:bounds}
    Under the conditions of Theorem~\ref{thm:bunea31}, there exists a constant \(C>0\) such that, for all \(a>0\) and integers \(n\geq 1\), \(M\geq 2\), and \(D\leq M\), the following holds:
    \[\E\normsq{f - \ftilde{\mathrm{BIC}}}\leq (1+a)\inf_{\lambda\in\Lambda}\normsq{f - \ftilde{\lambda}} + C(1+a+a^{-1})\frac{\sigma^{2}\psi_{n,M}}{n},\]
    where \(\Lambda\) and \(\psi_{n,M}\) are chosen accordingly as given in (\ref{eq:rates}).
\end{corollary}

\begin{myproofbox}
    We prove the case for the Model Selection scheme only, taking
    \[\Lambda = \Lambda_{\mathrm{MS}}\quad\text{and}\quad\psi_{n,M}=\frac{\log(M)}{n}.\]
    Note that, for \(\lambda\in\Lambda_{\mathrm{MS}}\), \(M(\lambda)=1\) and \(L(\lambda) = 2\log(eM)\). Thus,
    \begin{align*}
        &(1+a)\inf_{\lambda\in\Lambda_{\mathrm{MS}}}\set{\normsq{\ftilde{\lambda} - f} + \frac{\sigma^{2}}{n}\paren{5+\frac{2+3a}{a}{L(\lambda)}}M(\lambda)}\\
        &\qquad\qquad= (1+a)\inf_{\lambda\in\R^{M}}\set{\normsq{\ftilde{\lambda} - f}} + (1+a)\frac{\sigma^{2}}{n}\paren{5+\frac{2+3a}{a}\paren{2\log(eM)}}\\
        &\qquad\qquad\leq (1+a)\inf_{\lambda\in\R^{M}}\set{\normsq{\ftilde{\lambda} - f}} + C(1+a+a^{-1})\frac{\sigma^{2}}{n}\log(M).
    \end{align*}
    \qed{}
\end{myproofbox}

\subsection{Some remarks}

The BIC-type aggregation approach discussed in this section provides a general framework that adapts well to various model aggregation scenarios, with theoretical guarantees that approach the optimal rates established in Theorem~\ref{prop:buneath5.1}. Several key observations are worth highlighting:
\begin{enumerate}
    \item Flexibility of framework: The BIC-type penalty can be applied across multiple aggregation schemes while maintaining near-optimal convergence rates. This makes it particularly useful when the appropriate aggregation scheme is not obvious a priori.
    \item Computational considerations: While the theoretical results are encouraging, the computation of $\lambdahat{\text{BIC}}$ as defined in~\eqref{eq:weights} may be challenging in practice, especially for large values of $M$. For Linear and Convex aggregation schemes, the optimization problem is convex and thus tractable. However, for Model Selection and Subset Selection, which involve discrete optimization over a combinatorial space, exact computation may be infeasible for large $M$.
    \item Variance estimation: The practical implementation of the BIC-type penalty requires knowledge of $\sigma^2$, the variance of the residuals. In practice, this parameter is typically unknown and must be estimated from the data.
    \item Extension to heteroscedastic settings: The framework presented assumes homoscedastic, Gaussian errors. Extending the results to settings with heteroscedastic errors would be valuable for many practical applications where the assumption of constant variance is unrealistic.
\end{enumerate}

The aggregation approach presented in this section provides a theoretically sound framework for combining multiple candidate models, with guarantees that approach the optimal minimax rates. The flexibility of the framework makes it applicable across various model selection and aggregation scenarios, though practical implementation considerations remain to be addressed, particularly for large sets of candidate models. We will empirically evaluate the performance of this approach in the next section.


\section{Simulation study}\label{sec:simulations}


\newpage
\printbibliography{}
\end{document}